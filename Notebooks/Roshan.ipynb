{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eccc9cab",
   "metadata": {
    "id": "eccc9cab"
   },
   "source": [
    "<div style=\"background: linear-gradient(to right, #6a11cb, #2575fc); padding: 20px; border-radius: 10px; color: white;\">\n",
    "<h1 style=\"text-align: center; margin: 0;\">Pricing American options in rough Bergomi with linear and deep signatures</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ckOdm_OAGE",
   "metadata": {
    "id": "c9ckOdm_OAGE"
   },
   "source": [
    "<div style=\"background-color: #f8f9fa; padding: 15px; border-left: 5px solid #2575fc; margin: 10px 0;\">\n",
    "<p>In this notebook we show how to use the code from <a href=\"https://github.com/lucapelizzari/Optimal_Stopping_with_signatures/tree/main\" style=\"color: #2575fc; text-decoration: none; font-weight: bold;\">this GitHub repository</a>, to compute lower and upper bounds for American options in the rough Bergomi model using different signature methods, see for example Section 4.2 of <a href=\"https://arxiv.org/abs/2312.03444\" style=\"color: #2575fc; text-decoration: none; font-weight: bold;\">this paper</a> for the linear approach, whereas the deep neural network approaches will be discussed in a forthcoming paper.</p>\n",
    "\n",
    "<p>The repository consists of:</p>\n",
    "\n",
    "<ul style=\"list-style-type: none; padding-left: 20px;\">\n",
    "    <li><span style=\"color: #2575fc; font-weight: bold;\">→</span> Simulation packages for fractional Brownian motion, rough Bergomi and rough Heston models</li>\n",
    "    <li><span style=\"color: #2575fc; font-weight: bold;\">→</span> A modul for signature related computations <code style=\"background-color: #eef; padding: 2px 4px; border-radius: 3px;\">Signature_computer.py</code>, which can compute the signature and log-signature of various lifts related to volatility modelling, with the additional option of adding polynomials of the state-process and/or volatility.</li>\n",
    "    <li><span style=\"color: #2575fc; font-weight: bold;\">→</span> The main module for the linear signature approaches <code style=\"background-color: #eef; padding: 2px 4px; border-radius: 3px;\">Linear_signature_optimal_stopping.py</code>, which can be used to derive lower and upper bounds to the optimal stopping problem applying the approaches described in <a href=\"https://arxiv.org/abs/2312.03444\" style=\"color: #2575fc; text-decoration: none; font-weight: bold;\">the paper</a>.</li>\n",
    "    <li><span style=\"color: #2575fc; font-weight: bold;\">→</span> The main module for deep log-signature approaches <code style=\"background-color: #eef; padding: 2px 4px; border-radius: 3px;\">Deep_signature_optimal_stopping.py</code>, which extends the linear approaches by applying deep neural networks on the log-signature. This code is accompanying a working paper on \"American option pricing using signatures\".</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "bf5f07ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 07:49:20,021 - INFO - Loading data from /Users/roshanshah1/Downloads/Optimal_Stopping_with_signatures-main/XGboost_Roshan/src/data/dataset1.pkl\n",
      "2025-05-16 07:49:20,051 - INFO - Loaded 55440 rows and 8 columns from dataset1.pkl\n",
      "2025-05-16 07:49:20,052 - INFO - Loading data from /Users/roshanshah1/Downloads/Optimal_Stopping_with_signatures-main/XGboost_Roshan/src/data/dataset3.pkl\n",
      "2025-05-16 07:49:20,067 - INFO - Loaded 124798 rows and 4 columns from dataset3.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered data for AAPL on 2023-08-31 with 10 days:\n",
      "            date  days  forward_price  strike_price   premium  \\\n",
      "16610 2023-08-31    10     188.128433    188.128433  2.238860   \n",
      "16621 2023-08-31    10     188.128433    188.128433  2.081757   \n",
      "\n",
      "       impl_volatility cp_flag ticker  \n",
      "16610         0.180468       C   AAPL  \n",
      "16621         0.166286       P   AAPL  \n",
      "\n",
      " Extracted Model Inputs (PUTS):\n",
      "ticker: AAPL\n",
      "date: 2023-08-31 00:00:00\n",
      "T_years: 0.03968253968253968\n",
      "strike: 188.128433\n",
      "X0 (forward): 188.128433\n",
      "market_premium: 2.081757\n",
      "Estimated rho: -0.18\n",
      "\n",
      "✅ Global parameters set:\n",
      "N1 = 10, N = 252, T = 10, T_years = 0.03968\n",
      "M = 8192, M2 = 8192, eta = 1.9, X0 = 188.128433, strike = 188.128433\n",
      "r = 0.05, rho = -0.18, xi = 0.09, K = 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Global option model parameters (pre-initialized)\n",
    "N1 = 0         # number of exercise-dates\n",
    "N = 0          # discretization-grid\n",
    "T = 0          # Maturity in days\n",
    "T_years = 0.0  # Maturity in years\n",
    "M = 0          # number of training samples\n",
    "M2 = 0         # number of testing samples\n",
    "eta = 0.0      # volatility of volatility\n",
    "X0 = 0.0       # forward price (initial asset price)\n",
    "r = 0.0        # risk-free rate\n",
    "rho = 0.0      # correlation\n",
    "xi = 0.0       # initial forward variance\n",
    "strike = 0.0   # strike price\n",
    "K = 0          # signature depth\n",
    "\n",
    "# Payoff function\n",
    "def phi(x):\n",
    "    return np.maximum(strike - x, 0)\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "repo_root = os.path.abspath('..')\n",
    "notebook_dir = Path(repo_root) / 'XGboost_Roshan' / 'src'\n",
    "DATA_PICKLE = notebook_dir / 'data' / 'dataset1.pkl'\n",
    "RETURNS_PICKLE = notebook_dir / 'data' / 'dataset3.pkl'\n",
    "\n",
    "def load_and_clean_data(pickle_path):\n",
    "    if os.path.exists(pickle_path):\n",
    "        logger.info(f\"Loading data from {pickle_path}\")\n",
    "        df = pd.read_pickle(pickle_path)\n",
    "    else:\n",
    "        logger.warning(f\"Pickle file not found at {pickle_path}\")\n",
    "        os.makedirs(pickle_path.parent, exist_ok=True)\n",
    "        csv_path = pickle_path.with_suffix('.csv')\n",
    "        if os.path.exists(csv_path):\n",
    "            logger.info(f\"Found CSV at {csv_path}. Converting to pickle.\")\n",
    "            df = pd.read_csv(csv_path, parse_dates=['date'], dayfirst=False)\n",
    "            df.to_pickle(pickle_path)\n",
    "            logger.info(f\"Converted and saved as pickle: {pickle_path}\")\n",
    "        else:\n",
    "            logger.warning(f\"CSV file also not found at {csv_path}\")\n",
    "            return None\n",
    "\n",
    "    # Common cleanup\n",
    "    if 'secid' in df.columns or 'index_flag' in df.columns:\n",
    "        df = df.drop(columns=['secid', 'index_flag'], errors='ignore')\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    logger.info(f\"Loaded {df.shape[0]} rows and {df.shape[1]} columns from {pickle_path.name}\")\n",
    "    return df\n",
    "\n",
    "def select_data_by_date_and_days(df, target_date=None, days_length=None):\n",
    "    filtered_df = df.copy()\n",
    "    if target_date:\n",
    "        filtered_df = filtered_df[filtered_df['date'] == pd.to_datetime(target_date)]\n",
    "    if days_length is not None:\n",
    "        filtered_df = filtered_df[filtered_df['days'] == days_length]\n",
    "    return filtered_df\n",
    "\n",
    "def extract_model_inputs(option_df):\n",
    "    put_df = option_df[option_df['cp_flag'] == 'P']\n",
    "    if put_df.empty:\n",
    "        return None\n",
    "    row = put_df.iloc[0]\n",
    "    return {\n",
    "        \"ticker\": row['ticker'],\n",
    "        \"date\": row['date'],\n",
    "        \"T_years\": row['days'] / 252,\n",
    "        \"strike\": row['strike_price'],\n",
    "        \"X0 (forward)\": row['forward_price'],\n",
    "        \"market_premium\": row['premium']\n",
    "    }\n",
    "\n",
    "def estimate_rho(returns_df, options_df, target_ticker):\n",
    "    ret_df = returns_df[returns_df['ticker'] == target_ticker].copy()\n",
    "    opt_df = options_df[options_df['ticker'] == target_ticker].copy()\n",
    "\n",
    "    ret_df = ret_df.sort_values('date')\n",
    "    opt_df = opt_df.sort_values('date').drop_duplicates(subset=['date'])\n",
    "\n",
    "    merged = pd.merge(ret_df, opt_df[['date', 'impl_volatility']], on='date', how='inner')\n",
    "    merged['vol_change'] = merged['impl_volatility'].diff()\n",
    "    merged = merged.dropna(subset=['return', 'vol_change'])\n",
    "\n",
    "    if len(merged) < 2:\n",
    "        return None\n",
    "    return merged['return'].corr(merged['vol_change'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_and_clean_data(DATA_PICKLE)\n",
    "    returns_df = load_and_clean_data(RETURNS_PICKLE)\n",
    "\n",
    "    if df is not None and returns_df is not None:\n",
    "        date_input = input(\"Enter date (YYYY-MM-DD) [default: 2023-08-31]: \").strip()\n",
    "        target_date = date_input if date_input else \"2023-08-31\"\n",
    "\n",
    "        days_input = input(\"Enter option length in days [default: 10]: \").strip()\n",
    "        try:\n",
    "            days_length = int(days_input) if days_input else 10\n",
    "        except ValueError:\n",
    "            logger.warning(\"Invalid input for days. Defaulting to 10.\")\n",
    "            days_length = 10\n",
    "\n",
    "        ticker_input = input(\"Enter ticker [default: AAPL]: \").strip().upper()\n",
    "        ticker = ticker_input if ticker_input else \"AAPL\"\n",
    "\n",
    "        filtered_data = select_data_by_date_and_days(df, target_date, days_length)\n",
    "        ticker_data = filtered_data[filtered_data['ticker'] == ticker]\n",
    "\n",
    "        if len(ticker_data) > 0:\n",
    "            print(f\"\\nFiltered data for {ticker} on {target_date} with {days_length} days:\")\n",
    "            print(ticker_data)\n",
    "            model_inputs = extract_model_inputs(ticker_data)\n",
    "            if model_inputs:\n",
    "                print(\"\\n Extracted Model Inputs (PUTS):\")\n",
    "                for k, v in model_inputs.items():\n",
    "                    print(f\"{k}: {v}\")\n",
    "\n",
    "                rho_est = round(estimate_rho(returns_df, df, ticker),2)\n",
    "                print(f\"Estimated rho: {rho_est}\" if rho_est is not None else \"Rho estimation failed.\")\n",
    "                rho = rho_est if rho_est is not None else -0.9\n",
    "\n",
    "\n",
    "                N = 252\n",
    "                M = 2**13\n",
    "                M2 = 2**13\n",
    "                eta = 1.9\n",
    "                r = 0.05\n",
    "                xi = 0.09\n",
    "                K = 2\n",
    "\n",
    "                # Extracted from data\n",
    "                T = int(model_inputs[\"T_years\"] * 252)\n",
    "                # Global constants\n",
    "                N1 = T\n",
    "                T_years = model_inputs[\"T_years\"]\n",
    "                X0 = model_inputs[\"X0 (forward)\"]\n",
    "                strike = model_inputs[\"strike\"]\n",
    "\n",
    "                print(\"\\n✅ Global parameters set:\")\n",
    "                print(f\"N1 = {N1}, N = {N}, T = {T}, T_years = {T_years:.5f}\")\n",
    "                print(f\"M = {M}, M2 = {M2}, eta = {eta}, X0 = {X0}, strike = {strike}\")\n",
    "                print(f\"r = {r}, rho = {rho}, xi = {xi}, K = {K}\")\n",
    "            else:\n",
    "                logger.warning(\"No put option found for this filter.\")\n",
    "        else:\n",
    "            logger.warning(\"No data matches your filter criteria.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3e039383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n1 = 10, n = 252, T = 10, T_years = 0.03968, M = 8192, M2 = 8192, eta = 1.9, X0 = 188.12843, strike = 188.12843, r = 0.05000, rho = -0.18000, xi = 0.09000, K = 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"n1 = {N1}, n = {N}, T = {T}, T_years = {T_years:.5f}, M = {M}, M2 = {M2}, eta = {eta:}, X0 = {X0:.5f}, strike = {strike:.5f}, r = {r:.5f}, rho = {rho:.5f}, xi = {xi:.5f}, K = {K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "c5c7aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for TensorFlow import issues and environment compatibility\n",
    "# Set correct Python path to find modules\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the root directory and subdirectories to Python path\n",
    "repo_root = os.path.abspath('..')\n",
    "sys.path.append(repo_root)\n",
    "sys.path.append(os.path.join(repo_root, \"Linear signature optimal stopping\"))\n",
    "sys.path.append(os.path.join(repo_root, \"Non linear signature optimal stopping\"))\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e568a2",
   "metadata": {
    "id": "57e568a2"
   },
   "source": [
    "<div style=\"background: linear-gradient(to right, #2575fc, #6a11cb); padding: 10px; border-radius: 8px; margin: 15px 0;\">\n",
    "<h2 style=\"color: white; margin: 0; padding: 5px;\">American Put options in the rough Bergomi model</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572b688",
   "metadata": {
    "id": "6572b688"
   },
   "source": [
    "<div style=\"background-color: #f0f4f8; padding: 15px; border-radius: 5px; border-left: 5px solid #2575fc;\">\n",
    "Recall the price and volatility dynamics of the latter are given by \n",
    "<div style=\"text-align: center; margin: 10px 0;\">\n",
    "\\begin{align*}\n",
    "dX_t &= rX_tdt+X_tv_t \\left (\\rho dW_r+\\sqrt{1-\\rho^2}dB_t\\right ), \\\\ \n",
    "v_t & =\\xi_0\\mathcal{E}\\left (\\eta \\int_0^t(t-s)^{H-\\frac{1}{2}}dW_s \\right )\n",
    "\\end{align*}\n",
    "</div>\n",
    "and pricing an American Put-option can be formulated as optimal stopping problem \n",
    "<div style=\"text-align: center; margin: 10px 0;\">\n",
    "$$y_0=\\sup_{\\tau \\in \\mathcal{S}_0}\\mathbb{E}[e^{-r\\tau}\\left (K-X_{\\tau}\\right )^{+}]$$\n",
    "</div>\n",
    "for some strike $K$. In this notebook we consider the following choice of paramteres \n",
    "<div style=\"text-align: center; margin: 10px 0; font-weight: bold; color: #2575fc;\">\n",
    "$$ H=0.07,X_0 = 100, r=0.05, \\eta = 1.9, \\rho = -0.9, \\xi_0= 0.09, K = 110.$$\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xlp80cKeRW9z",
   "metadata": {
    "id": "Xlp80cKeRW9z"
   },
   "source": [
    "<div style=\"background: linear-gradient(to right, #2575fc, #6a11cb); padding: 10px; border-radius: 8px; margin: 15px 0;\">\n",
    "<h2 style=\"color: white; margin: 0; padding: 5px;\">Step 1: Simulation rough Bergomi model</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I7PTV1Z3Rig-",
   "metadata": {
    "id": "I7PTV1Z3Rig-"
   },
   "source": [
    "<div style=\"background-color: #f0f4f8; padding: 15px; border-radius: 5px;\">\n",
    "We start by defining the parameters of the model and importing the rough Berogmi simulation package.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1809c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining hurst parameter... last official step to figure out\n",
    "H = 0.07  # Hurst parameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61KWkP-iYnFJ",
   "metadata": {
    "id": "61KWkP-iYnFJ"
   },
   "source": [
    "<div style=\"background-color: #fff4e6; padding: 12px; border-radius: 5px; border-left: 4px solid #fd7e14; margin: 10px 0;\">\n",
    "<p><span style=\"font-weight: bold; color: #fd7e14;\">⚠️ Note:</span> The number of samples should be much bigger to get reliable results, but to keep the complexity low in this presentation we restrict to $2^{15}$ training and testing paths here.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "7057f779",
   "metadata": {
    "id": "7057f779"
   },
   "outputs": [],
   "source": [
    "# Adjust path to include repository root\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from rBergomi_simulation import SimulationofrBergomi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29669ebe",
   "metadata": {
    "id": "29669ebe"
   },
   "source": [
    "<div style=\"background-color: #f0f4f8; padding: 15px; border-radius: 5px; border-left: 5px solid #2575fc;\">\n",
    "Next we define a function generating rough Bergomi prices, volatilies and the corresponding Brownian motion and payoff process. Then we generate training and testing data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "9cd21314",
   "metadata": {
    "id": "9cd21314"
   },
   "outputs": [],
   "source": [
    "def generate_data(M, N, T_years, phi, rho, K, X0, H, xi, eta, r):\n",
    "    X, V, I, dI, dW1, dW2, dB, Y = SimulationofrBergomi(M, N, T_years, phi, rho, K, X0, H, xi, eta, r)\n",
    "\n",
    "    # Calculate Payoff\n",
    "    Payoff = phi(X)\n",
    "\n",
    "    # Stack state and volatility into features for signature\n",
    "    MM = np.stack([X, V], axis=-1)\n",
    "\n",
    "    return X, V, Payoff, dW1, I, MM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7c86a8cc",
   "metadata": {
    "id": "7c86a8cc"
   },
   "outputs": [],
   "source": [
    "# Use K in your function call, not strike\n",
    "S_training, V_training, Payoff_training, dW_training, I_training, MM_training = generate_data(M, N, T_years, phi, rho, K, X0, H, xi, eta, r)\n",
    "S_testing, V_testing, Payoff_testing, dW_testing, I_testing, MM_testing = generate_data(M2, N, T_years, phi, rho, K, X0, H, xi, eta, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bb1fef55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show Head of the training data\n",
      "S_training [[1.         1.02366161 1.01558289 1.01791001 1.01265106 1.0139968\n",
      "  1.01537034 1.0247938  1.03205779 1.03314347 1.03728687 1.03866331\n",
      "  1.03834839 1.04221617 1.04320711]\n",
      " [1.         1.00404953 0.98661537 1.02117389 1.02137071 1.02069033\n",
      "  1.02503354 1.01508967 1.02479632 1.03215783 1.03307057 1.02356082\n",
      "  1.01810729 0.97814946 1.01635097]\n",
      " [1.         1.01679544 1.01196769 1.01451727 1.03600187 1.03289542\n",
      "  1.02970534 1.0268663  1.00123735 0.99700164 1.01434144 1.01544836\n",
      "  1.00956719 0.99569058 0.9964671 ]\n",
      " [1.         1.00946391 1.01047207 1.00853031 0.98832992 0.96208366\n",
      "  0.9980605  0.99526411 0.99474903 1.00422758 0.98878723 0.96679287\n",
      "  0.96394657 0.95236486 0.93847845]\n",
      " [1.         1.00420544 1.01851017 1.01591762 1.01228992 1.01158605\n",
      "  1.01723176 1.01484748 1.03461381 1.03117454 1.03558265 1.03878542\n",
      "  1.04716524 1.04781743 1.03915182]]\n",
      "V_training [[9.00000000e-02 2.87867832e-02 1.20944629e-02 5.34851416e-02\n",
      "  2.64231033e-02 3.55949787e-03 9.36820386e-03 8.45285941e-03\n",
      "  1.29980694e-03 1.13702035e-02 1.77833802e-02 5.85051990e-03\n",
      "  2.17000819e-03 1.68858305e-03 1.52980135e-02]\n",
      " [9.00000000e-02 1.15190027e-01 6.28568433e-02 2.29486903e-03\n",
      "  4.06384323e-02 3.77295281e-02 2.43890034e-02 9.82671043e-02\n",
      "  5.06740632e-02 1.56500991e-02 3.62254943e-02 3.17634654e-02\n",
      "  1.40413773e-01 2.13335264e-01 3.58481158e-03]\n",
      " [9.00000000e-02 3.50465057e-03 1.99279594e-02 5.38603914e-02\n",
      "  9.72042913e-02 2.70644361e-02 4.25053668e-03 4.08177170e-02\n",
      "  5.65690756e-02 7.54221535e-02 3.10974742e-02 9.80492175e-02\n",
      "  3.51554447e-02 5.16648525e-02 1.35320016e-01]\n",
      " [9.00000000e-02 2.76622717e-02 1.39237398e-02 6.69723518e-02\n",
      "  7.13863844e-02 7.70497012e-02 2.92417600e-02 3.55644461e-03\n",
      "  8.04070050e-02 5.70478843e-02 6.71071070e-01 6.72944117e-02\n",
      "  1.21301272e-01 2.50492564e-02 6.47598841e-01]\n",
      " [9.00000000e-02 3.05950379e-01 1.31613223e-02 3.34687864e-02\n",
      "  4.95859036e-03 3.34287961e-02 8.78173911e-03 4.22921588e-02\n",
      "  4.07967885e-03 6.71040294e-03 1.33824070e-02 7.97826686e-03\n",
      "  3.26863818e-04 4.12198987e-03 8.68988022e-02]]\n",
      "Payoff_training [[0.05       0.02633839 0.03441711 0.03208999 0.03734894 0.0360032\n",
      "  0.03462966 0.0252062  0.01794221 0.01685653 0.01271313 0.01133669\n",
      "  0.01165161 0.00778383 0.00679289]\n",
      " [0.05       0.04595047 0.06338463 0.02882611 0.02862929 0.02930967\n",
      "  0.02496646 0.03491033 0.02520368 0.01784217 0.01692943 0.02643918\n",
      "  0.03189271 0.07185054 0.03364903]\n",
      " [0.05       0.03320456 0.03803231 0.03548273 0.01399813 0.01710458\n",
      "  0.02029466 0.0231337  0.04876265 0.05299836 0.03565856 0.03455164\n",
      "  0.04043281 0.05430942 0.0535329 ]\n",
      " [0.05       0.04053609 0.03952793 0.04146969 0.06167008 0.08791634\n",
      "  0.0519395  0.05473589 0.05525097 0.04577242 0.06121277 0.08320713\n",
      "  0.08605343 0.09763514 0.11152155]\n",
      " [0.05       0.04579456 0.03148983 0.03408238 0.03771008 0.03841395\n",
      "  0.03276824 0.03515252 0.01538619 0.01882546 0.01441735 0.01121458\n",
      "  0.00283476 0.00218257 0.01084818]]\n",
      "dW_training [[[-5.29942813e-02 -4.32669134e-01]\n",
      "  [ 1.20123607e-02 -1.04756460e+00]\n",
      "  [-2.57033377e-02  9.10142216e-01]\n",
      "  [ 3.97990916e-02  1.79458314e-01]\n",
      "  [-4.32712944e-02 -3.03028860e+00]\n",
      "  [-3.17303033e-04 -1.20317273e+00]\n",
      "  [-1.17310160e-01 -1.38323710e+00]\n",
      "  [-6.50631957e-02 -2.95377796e+00]\n",
      "  [-3.22052564e-02  4.72333616e-01]\n",
      "  [-5.24927765e-02  1.16074124e+00]\n",
      "  [-6.02541934e-02 -1.18612636e-01]\n",
      "  [-2.47214306e-02 -1.18302828e+00]\n",
      "  [-5.38688798e-02 -1.56109442e+00]\n",
      "  [ 1.42392900e-02  1.82688320e+00]]\n",
      "\n",
      " [[-1.90772473e-02  1.51786925e+00]\n",
      "  [ 9.03935203e-02  9.59947586e-01]\n",
      "  [-1.40125986e-01 -4.48477138e+00]\n",
      "  [ 1.42349475e-02  1.04751232e+00]\n",
      "  [-1.33297073e-02  6.74223737e-01]\n",
      "  [-3.81117446e-03  1.57315031e-01]\n",
      "  [ 6.04066515e-02  2.11905974e+00]\n",
      "  [-5.59311692e-03  6.13140194e-01]\n",
      "  [-4.07222499e-02 -8.84457863e-01]\n",
      "  [-3.67328792e-03  7.16322655e-01]\n",
      "  [ 1.10566429e-01  5.23646829e-01]\n",
      "  [ 2.05616193e-02  1.58130330e+00]\n",
      "  [ 3.03233573e-02  2.18045062e+00]\n",
      "  [-1.32218069e-01 -3.69777415e+00]]\n",
      "\n",
      " [[-9.41085605e-02 -3.39480361e+00]\n",
      "  [ 8.03881651e-02  3.16108436e-02]\n",
      "  [ 3.12147790e-03  5.93557504e-01]\n",
      "  [-7.07021672e-02  1.50763137e+00]\n",
      "  [ 4.63635531e-02  4.26767432e-01]\n",
      "  [-6.85826870e-03 -2.68463317e+00]\n",
      "  [-5.71814442e-03  6.14765891e-01]\n",
      "  [ 1.34035749e-01  1.14593749e+00]\n",
      "  [ 1.93153314e-02  3.29788977e-01]\n",
      "  [-5.93733795e-02 -8.32745266e-01]\n",
      "  [-6.30257066e-03  1.50785212e+00]\n",
      "  [-1.97259905e-02  1.30398416e-01]\n",
      "  [ 3.56680092e-02  8.68909449e-01]\n",
      "  [ 1.87086799e-02  1.88351926e+00]]\n",
      "\n",
      " [[-5.76558250e-02 -4.88719319e-01]\n",
      "  [-4.63984372e-04 -8.06728902e-01]\n",
      "  [-1.24763340e-02  1.37481039e+00]\n",
      "  [ 1.00372921e-01  1.57672576e+00]\n",
      "  [ 1.06250261e-01  7.48284864e-01]\n",
      "  [-9.11366759e-02 -1.40295413e+00]\n",
      "  [-2.54491198e-03 -3.22970929e+00]\n",
      "  [ 2.44372906e-02  1.18762786e+00]\n",
      "  [-4.18725424e-02  5.09316576e-01]\n",
      "  [ 1.07341937e-01  4.43850372e+00]\n",
      "  [ 3.89985725e-02  1.97747848e-01]\n",
      "  [ 3.05378376e-02  8.72711378e-01]\n",
      "  [-1.03161256e-02 -1.43509368e+00]\n",
      "  [ 1.41781104e-01  3.41411255e+00]]\n",
      "\n",
      " [[ 4.16441685e-02  2.89192928e+00]\n",
      "  [-4.69239976e-02 -1.79583622e+00]\n",
      "  [ 5.42768709e-02  9.99467126e-02]\n",
      "  [ 2.61575351e-03 -3.07320560e+00]\n",
      "  [-2.68139480e-02 -2.86296441e-01]\n",
      "  [-1.20481499e-01 -1.83501333e+00]\n",
      "  [ 3.75448849e-02  1.49384186e+00]\n",
      "  [-1.14890667e-01 -2.33966754e+00]\n",
      "  [ 6.53791460e-02 -6.11202336e-01]\n",
      "  [-8.21368213e-02 -4.69488393e-01]\n",
      "  [-2.31223520e-02 -4.45688502e-01]\n",
      "  [-1.14175008e-01 -4.89435359e+00]\n",
      "  [ 2.35118445e-02 -4.19862734e-01]\n",
      "  [ 1.30017753e-01  3.35433577e+00]]]\n",
      "I_training [[ 0.         -0.01589828 -0.01386019 -0.01668691 -0.00748263 -0.01451646\n",
      "  -0.01453539 -0.02588978 -0.03187165 -0.03303274 -0.03863011 -0.04666527\n",
      "  -0.04855618 -0.05106557 -0.05048044]\n",
      " [ 0.         -0.00572317  0.02495608 -0.01017528 -0.00949336 -0.01218049\n",
      "  -0.01292078 -0.00348709 -0.00524039 -0.01440734 -0.01486687  0.00617724\n",
      "   0.00984179  0.02120451 -0.03986468]\n",
      " [ 0.         -0.02823257 -0.02347358 -0.02303293 -0.03944138 -0.02498634\n",
      "  -0.02611461 -0.02648741  0.00059236  0.00518637 -0.0111194  -0.01223082\n",
      "  -0.01840758 -0.01171991 -0.00746744]\n",
      " [ 0.         -0.01729675 -0.01737392 -0.01884611  0.00712941  0.0355176\n",
      "   0.01022004  0.00978486  0.0112422  -0.00063123  0.02500706  0.05695428\n",
      "   0.06487615  0.06128321  0.08372285]\n",
      " [ 0.          0.01249325 -0.01346172 -0.00723492 -0.00675638 -0.00864455\n",
      "  -0.03067284 -0.02715447 -0.0507818  -0.04660588 -0.05333429 -0.05600914\n",
      "  -0.06620738 -0.0657823  -0.0574348 ]]\n",
      "MM_training [[[1.00000000e+00 9.00000000e-02]\n",
      "  [1.02366161e+00 2.87867832e-02]\n",
      "  [1.01558289e+00 1.20944629e-02]\n",
      "  [1.01791001e+00 5.34851416e-02]\n",
      "  [1.01265106e+00 2.64231033e-02]\n",
      "  [1.01399680e+00 3.55949787e-03]\n",
      "  [1.01537034e+00 9.36820386e-03]\n",
      "  [1.02479380e+00 8.45285941e-03]\n",
      "  [1.03205779e+00 1.29980694e-03]\n",
      "  [1.03314347e+00 1.13702035e-02]\n",
      "  [1.03728687e+00 1.77833802e-02]\n",
      "  [1.03866331e+00 5.85051990e-03]\n",
      "  [1.03834839e+00 2.17000819e-03]\n",
      "  [1.04221617e+00 1.68858305e-03]\n",
      "  [1.04320711e+00 1.52980135e-02]]\n",
      "\n",
      " [[1.00000000e+00 9.00000000e-02]\n",
      "  [1.00404953e+00 1.15190027e-01]\n",
      "  [9.86615366e-01 6.28568433e-02]\n",
      "  [1.02117389e+00 2.29486903e-03]\n",
      "  [1.02137071e+00 4.06384323e-02]\n",
      "  [1.02069033e+00 3.77295281e-02]\n",
      "  [1.02503354e+00 2.43890034e-02]\n",
      "  [1.01508967e+00 9.82671043e-02]\n",
      "  [1.02479632e+00 5.06740632e-02]\n",
      "  [1.03215783e+00 1.56500991e-02]\n",
      "  [1.03307057e+00 3.62254943e-02]\n",
      "  [1.02356082e+00 3.17634654e-02]\n",
      "  [1.01810729e+00 1.40413773e-01]\n",
      "  [9.78149458e-01 2.13335264e-01]\n",
      "  [1.01635097e+00 3.58481158e-03]]\n",
      "\n",
      " [[1.00000000e+00 9.00000000e-02]\n",
      "  [1.01679544e+00 3.50465057e-03]\n",
      "  [1.01196769e+00 1.99279594e-02]\n",
      "  [1.01451727e+00 5.38603914e-02]\n",
      "  [1.03600187e+00 9.72042913e-02]\n",
      "  [1.03289542e+00 2.70644361e-02]\n",
      "  [1.02970534e+00 4.25053668e-03]\n",
      "  [1.02686630e+00 4.08177170e-02]\n",
      "  [1.00123735e+00 5.65690756e-02]\n",
      "  [9.97001637e-01 7.54221535e-02]\n",
      "  [1.01434144e+00 3.10974742e-02]\n",
      "  [1.01544836e+00 9.80492175e-02]\n",
      "  [1.00956719e+00 3.51554447e-02]\n",
      "  [9.95690580e-01 5.16648525e-02]\n",
      "  [9.96467096e-01 1.35320016e-01]]\n",
      "\n",
      " [[1.00000000e+00 9.00000000e-02]\n",
      "  [1.00946391e+00 2.76622717e-02]\n",
      "  [1.01047207e+00 1.39237398e-02]\n",
      "  [1.00853031e+00 6.69723518e-02]\n",
      "  [9.88329920e-01 7.13863844e-02]\n",
      "  [9.62083656e-01 7.70497012e-02]\n",
      "  [9.98060497e-01 2.92417600e-02]\n",
      "  [9.95264107e-01 3.55644461e-03]\n",
      "  [9.94749029e-01 8.04070050e-02]\n",
      "  [1.00422758e+00 5.70478843e-02]\n",
      "  [9.88787225e-01 6.71071070e-01]\n",
      "  [9.66792871e-01 6.72944117e-02]\n",
      "  [9.63946565e-01 1.21301272e-01]\n",
      "  [9.52364861e-01 2.50492564e-02]\n",
      "  [9.38478448e-01 6.47598841e-01]]\n",
      "\n",
      " [[1.00000000e+00 9.00000000e-02]\n",
      "  [1.00420544e+00 3.05950379e-01]\n",
      "  [1.01851017e+00 1.31613223e-02]\n",
      "  [1.01591762e+00 3.34687864e-02]\n",
      "  [1.01228992e+00 4.95859036e-03]\n",
      "  [1.01158605e+00 3.34287961e-02]\n",
      "  [1.01723176e+00 8.78173911e-03]\n",
      "  [1.01484748e+00 4.22921588e-02]\n",
      "  [1.03461381e+00 4.07967885e-03]\n",
      "  [1.03117454e+00 6.71040294e-03]\n",
      "  [1.03558265e+00 1.33824070e-02]\n",
      "  [1.03878542e+00 7.97826686e-03]\n",
      "  [1.04716524e+00 3.26863818e-04]\n",
      "  [1.04781743e+00 4.12198987e-03]\n",
      "  [1.03915182e+00 8.68988022e-02]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Show Head of the training data\")\n",
    "print(\"S_training\", S_training[:5])\n",
    "print(\"V_training\", V_training[:5])\n",
    "print(\"Payoff_training\", Payoff_training[:5])\n",
    "print(\"dW_training\", dW_training[:5])\n",
    "print(\"I_training\", I_training[:5])\n",
    "print(\"MM_training\", MM_training[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "68169f97",
   "metadata": {
    "id": "68169f97"
   },
   "outputs": [],
   "source": [
    "#compute the volatility processes\n",
    "vol_training = np.sqrt(V_training)\n",
    "vol_testing = np.sqrt(V_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LW4SLN7bQy4R",
   "metadata": {
    "id": "LW4SLN7bQy4R"
   },
   "source": [
    "<div style=\"background: linear-gradient(to right, #2575fc, #6a11cb); padding: 10px; border-radius: 8px; margin: 15px 0;\">\n",
    "<h2 style=\"color: white; margin: 0; padding: 5px;\">Step 2: Signature computations</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NUEKCKWsRPy4",
   "metadata": {
    "id": "NUEKCKWsRPy4"
   },
   "source": [
    "<div style=\"background-color: #f0f4f8; padding: 15px; border-radius: 5px;\">\n",
    "We will make us uf the <a href=\"https://pypi.org/project/iisignature/\" style=\"color: #2575fc; text-decoration: none; font-weight: bold;\">iisignature package</a> to compute the signature, and it can be installed using pip:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14790b8",
   "metadata": {
    "id": "d14790b8"
   },
   "source": [
    "<div style=\"background-color: #f0f4f8; padding: 15px; border-radius: 5px;\">\n",
    "We import our signature computation module, which can compute various signature and log signature lift related to the generated data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "1fa867a0",
   "metadata": {
    "id": "1fa867a0"
   },
   "outputs": [],
   "source": [
    "from Signature_computer import SignatureComputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2eb781",
   "metadata": {
    "id": "fe2eb781"
   },
   "source": [
    "<div style=\"background-color: #f0f4f8; padding: 15px; border-radius: 5px; border-left: 5px solid #2575fc;\">\n",
    "<p>Next we initialize the <code style=\"background-color: #eef; padding: 2px 4px; border-radius: 3px;\">SignatureComputer</code>, which allows to choose from the linear and the log signature, and various choices of signature lifts. Here are some examples:</p>\n",
    "<div style=\"text-align: center; background-color: #f8f9fa; padding: 10px; margin: 10px 0; border-radius: 5px;\">\n",
    "$$ t\\mapsto \\mathrm{Sig}(A_t,X_t),t\\mapsto \\mathrm{Sig}(A_t,\\phi(X)_t),t\\mapsto \\mathrm{Sig}(A_t,X_t,X_{t-\\epsilon}),t\\mapsto \\mathrm{Sig}(A_t,X_t,\\phi(X_t)),t\\mapsto \\mathrm{Sig}(A_t,v_t),$$\n",
    "</div>\n",
    "<p>where $t\\mapsto A_t$ is a monoton path and in our examples we choose between:</p>\n",
    "<div style=\"text-align: center; font-weight: bold; color: #2575fc; margin: 10px 0;\">\n",
    "$$A_t=t, \\quad  A_t = \\langle X\\rangle_t.$$\n",
    "</div>\n",
    "<p>Additonally we can add Laguerre polynomials of $X$ or $(X,v)$ to the signature, see the module for all the details.</p>\n",
    "<p>In this example we choose the basis $(\\mathrm{Sig}(t,v_t),p_i(X_t))$, which proves to be a solid choice for rough volatility models. We choose both the polynomial and signature degree to be $3$ for this example. (To improve result one should higher truncations levels ($4-5$) for the signature, but to keep the complexity reasonable here we choose level $3$ signatures.)</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "8c4a377c",
   "metadata": {
    "id": "8c4a377c"
   },
   "outputs": [],
   "source": [
    "#initialize signature computer\n",
    "sig_computer = SignatureComputer(T, N, 3, \"linear\", signature_lift=\"polynomial-vol\", poly_degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8c365145",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c365145",
    "outputId": "d26148d9-199d-4ebd-bd3f-60524818666b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing linear signature with polynomial-vol lift\n",
      "Computing linear signature with polynomial-vol lift\n"
     ]
    }
   ],
   "source": [
    "#Compute the signature for training and test data\n",
    "tt = np.linspace(0,T,N+1)\n",
    "A_training = np.zeros((M, N+1)) #time-augmentation\n",
    "A_testing = np.zeros((M2, N+1))\n",
    "A_training[:, 1:] = A_testing[:, 1:] = tt[1:]\n",
    "signatures_training = sig_computer.compute_signature(\n",
    "    S_training, vol_training, A_training, Payoff_training,\n",
    "    dW_training, I_training, MM_training\n",
    ")\n",
    "signatures_testing = sig_computer.compute_signature(\n",
    "    S_testing, vol_testing, A_testing, Payoff_testing,\n",
    "    dW_testing, I_testing, MM_testing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B0iPgqVDUXyd",
   "metadata": {
    "id": "B0iPgqVDUXyd"
   },
   "source": [
    "<div style=\"background-color: #f0f4f8; padding: 15px; border-radius: 5px;\">\n",
    "<p style=\"font-weight: bold; color: #2575fc;\">Some examples of the signature paths:</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "qLgGhAQqUa-K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "qLgGhAQqUa-K",
    "outputId": "e276704a-7235-49f0-98cd-04e9f91b9cdf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17899a5c0>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(signatures_training[0,:,0],label = 'first level (constant)')\n",
    "plt.plot(signatures_training[0,:,1],label = '1st level: time ')\n",
    "plt.plot(signatures_training[0,:,2],label = '2nd level: $v_t-v_0$')\n",
    "plt.plot(signatures_training[0,:,4],label = '3th level: $\\int sdv_s $')\n",
    "plt.plot(signatures_training[0,:,12],label = '4th level: $\\int \\int udv_u dv_s $')\n",
    "plt.legend(loc='upper right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19711264",
   "metadata": {
    "id": "19711264"
   },
   "source": [
    "<div style=\"background: linear-gradient(to right, #2575fc, #6a11cb); padding: 10px; border-radius: 8px; margin: 15px 0;\">\n",
    "<h2 style=\"color: white; margin: 0; padding: 5px;\">Step 3: Compute pricing intervals with linear signatures</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c7788",
   "metadata": {
    "id": "180c7788"
   },
   "source": [
    "<div style=\"background-color: #f0f4f8; padding: 15px; border-radius: 5px; border-left: 5px solid #2575fc;\">\n",
    "<p>We can now import the linear primal and dual pricers, which compute true lower and upper bounds.</p>\n",
    "<ul style=\"list-style-type: none; padding-left: 20px;\">\n",
    "    <li><span style=\"color: #2575fc; font-weight: bold;\">→</span> The <code style=\"background-color: #eef; padding: 2px 4px; border-radius: 3px;\">LinearLongstaffSchwartzPricer</code> uses the signature of the training data to recursively approximate continuation values in the spirit of the Longstaff-Schwartz algorithm (descibed in detail in Section 3.1 of <a href=\"https://arxiv.org/abs/2312.03444\" style=\"color: #2575fc; text-decoration: none; font-weight: bold;\">this paper</a>). The resulting regression coefficients at each exercise date provide a stopping rule, which can be applied to the testing data to get true lower-bounds</li>\n",
    "    <li><span style=\"color: #2575fc; font-weight: bold;\">→</span> The <code style=\"background-color: #eef; padding: 2px 4px; border-radius: 3px;\">LinearDualPricer</code> uses the signature of the training data to minimize over the familiy of linear signature martingales, by solving a corresponding linear program (described in Detail in Section 3.2 of <a href=\"https://arxiv.org/abs/2312.03444\" style=\"color: #2575fc; text-decoration: none; font-weight: bold;\">this paper</a>). The resulting coefficients yield a Doob martingale approximation, which for the testing data yields a true upper bound.</li>\n",
    "</ul>\n",
    "<p>By combining the two values, we receive confidence intervals for the true option price.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eTaJQW5V8q6",
   "metadata": {
    "id": "1eTaJQW5V8q6"
   },
   "source": [
    "<div style=\"background-color: #fff4e6; padding: 12px; border-radius: 5px; border-left: 4px solid #fd7e14; margin: 10px 0;\">\n",
    "<p>To solve the linear programm, one can optionally choose to use <a href=\"https://www.gurobi.com\" style=\"color: #fd7e14; text-decoration: none; font-weight: bold;\">Gurobi</a>, which requires a free licence, which is recommended especially for high-dimensional LPs, which occur when choosing large sample-sizes and/or high signature truncations levels. Alternatively, we use the free LP solvers from CVXPY</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "edbc73ec",
   "metadata": {
    "id": "edbc73ec"
   },
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# add root of repo and the “Linear signature optimal stopping” folder to PYTHONPATH\n",
    "import sys, os\n",
    "repo_root = os.path.abspath(\"..\")  # /Users/.../Optimal_Stopping_with_signatures\n",
    "ls_folder = os.path.join(repo_root, \"Linear signature optimal stopping\")\n",
    "sys.path.extend([repo_root, ls_folder])\n",
    "\n",
    "# now the module can be imported\n",
    "from Linear_signature_optimal_stopping import LinearLongstaffSchwartzPricer, LinearDualPricer\n",
    "# ────────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5a888326",
   "metadata": {
    "id": "5a888326"
   },
   "outputs": [],
   "source": [
    "\n",
    "#initialze the models\n",
    "ls_pricer = LinearLongstaffSchwartzPricer(\n",
    "        N1=N1,\n",
    "        T=T_years,\n",
    "        r=r,\n",
    "        mode=\"American Option\",\n",
    "        ridge=10**(-9)\n",
    "    )\n",
    "\n",
    "dual_pricer = LinearDualPricer(\n",
    "        N1=N1,\n",
    "        N=N,\n",
    "        T=T_years,\n",
    "        r=r,\n",
    "        LP_solver=\"CVXPY\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28db4f4d",
   "metadata": {
    "id": "28db4f4d"
   },
   "source": [
    "The choice mode=\"American Option\" indicates that the Longstaff-Schwartz recursion will only consider \"in-the-money\" paths, which was originally suggested by Longstaff & Schwartz, and is reasonable for non-negative payoffs. For general payoffs we can use mode = \"Standard\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "0889e9a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0889e9a8",
    "outputId": "8afb4b10-9708-46a7-f241-da85ac65ee99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression score at exercise date 13 0.9230387994767344\n",
      "Regression score at exercise date 12 0.8547423242465029\n",
      "Regression score at exercise date 11 0.8254892738204396\n",
      "Regression score at exercise date 10 0.7666234289692556\n",
      "Regression score at exercise date 9 0.7140860456598603\n",
      "Regression score at exercise date 8 0.6602038367312737\n",
      "Regression score at exercise date 7 0.5951556651683019\n",
      "Regression score at exercise date 6 0.5382641887519765\n",
      "Regression score at exercise date 5 0.4912708706639649\n",
      "Regression score at exercise date 4 0.4125772563404657\n",
      "Regression score at exercise date 3 0.3382086908456857\n",
      "Regression score at exercise date 2 0.2314366835999213\n",
      "Regression score at exercise date 1 0.11278063759931978\n"
     ]
    }
   ],
   "source": [
    "#compute true lower bounds\n",
    "lower_bound, lower_bound_std, ls_regression_models = ls_pricer.price(\n",
    "        signatures_training,\n",
    "        Payoff_training,\n",
    "        signatures_testing,\n",
    "        Payoff_testing\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e64a34fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e64a34fa",
    "outputId": "b116657f-4c30-4379-dbfb-5aa71549133d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Longstaff-Schwartz lower bound: 0.0534315029464392 ± 0.0005098966689766467\n"
     ]
    }
   ],
   "source": [
    "print(f\"Linear Longstaff-Schwartz lower bound: {lower_bound} ± {lower_bound_std/np.sqrt(M2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a51c2",
   "metadata": {
    "id": "676a51c2"
   },
   "source": [
    "Similarly let us derive the upper bounds, but we will train the model only for $M= 5000$ paths to reduce computation time, and then compute true prices for all testing samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "08fba8b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08fba8b2",
    "outputId": "710b6932-eb7b-4111-c511-20de6dd42eb6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.20 seconds needed to solve the linear program using CVXPY\n"
     ]
    }
   ],
   "source": [
    "M_dual = 5000\n",
    "upper_bound, upper_bound_std, MG = dual_pricer.price(\n",
    "        signatures_training[:M_dual],\n",
    "        Payoff_training[:M_dual],\n",
    "        dW_training[:M_dual,:,0],  # Select only the first component of the Brownian increments\n",
    "        signatures_testing,\n",
    "        Payoff_testing,\n",
    "        dW_testing[:,:,0]  # Select only the first component of the Brownian increments\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "39d591c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39d591c8",
    "outputId": "e078ca47-ef36-4133-d227-c6d2b88c391d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Dual upper bound: 0.06699659644005387 ± 2.2986797798329457e-06\n",
      "Pricing interval: (0.0534315029464392, 0.06699659644005387)± 0.0005098966689766467 \n"
     ]
    }
   ],
   "source": [
    "print(f\"Linear Dual upper bound: {upper_bound} ± {upper_bound_std/np.sqrt(M2)}\")\n",
    "print(f\"Pricing interval: {(float(lower_bound),float(upper_bound))}± {np.maximum(upper_bound_std,lower_bound_std)/np.sqrt(M2)} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ab12b0",
   "metadata": {
    "id": "06ab12b0"
   },
   "source": [
    "# Improving the duality gap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hir98wJJXKE8",
   "metadata": {
    "id": "hir98wJJXKE8"
   },
   "source": [
    "Especially in rough regimes (here $H=0.1$), we observe a significant gap between lower and upper bounds, and in this section we present two ways to improve it. The first one still relies on linear signatures, but extends the basis as explained in in Section 4 of https://arxiv.org/abs/2312.03444."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7ea7df",
   "metadata": {
    "id": "4d7ea7df"
   },
   "source": [
    "## Part 1: Extending the linear basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beffb042",
   "metadata": {
    "id": "beffb042"
   },
   "source": [
    "We consider a more involved basis by choosing the extended signature lift of $(t,X_t,\\phi(X_t))$, and additionally add Laguerre polynomials of $(X_t,v_t)$. We can again use the SignatureComputer to compute this extended basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "1eb54f12",
   "metadata": {
    "id": "1eb54f12"
   },
   "outputs": [],
   "source": [
    "sig_computer_extended = SignatureComputer(T, N, 3, \"linear\", signature_lift=\"payoff-and-polynomial-extended\", poly_degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "33d6249a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33d6249a",
    "outputId": "53179ca8-2f48-4b44-b1eb-99f3548c0900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing linear signature with payoff-and-polynomial-extended lift\n",
      "Computing linear signature with payoff-and-polynomial-extended lift\n"
     ]
    }
   ],
   "source": [
    "signatures_extended_training = sig_computer_extended.compute_signature(\n",
    "    S_training, vol_training, A_training, Payoff_training,\n",
    "    dW_training, I_training, MM_training\n",
    ")\n",
    "signatures_extended_testing = sig_computer_extended.compute_signature(\n",
    "    S_testing, vol_testing, A_testing, Payoff_testing,\n",
    "    dW_testing, I_testing, MM_testing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5zFWMoC-X-kM",
   "metadata": {
    "id": "5zFWMoC-X-kM"
   },
   "source": [
    "Now we repeat the procedure for the extended basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "1c2d3960",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "1c2d3960",
    "outputId": "009708e1-bce5-42b9-861f-3f437c5136e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression score at exercise date 13 0.9233911243553715\n",
      "Regression score at exercise date 12 0.8599873400607905\n",
      "Regression score at exercise date 11 0.8305999636579253\n",
      "Regression score at exercise date 10 0.7689441195976593\n",
      "Regression score at exercise date 9 0.7305343238629651\n",
      "Regression score at exercise date 8 0.6994314294269418\n",
      "Regression score at exercise date 7 0.6400584891405384\n",
      "Regression score at exercise date 6 0.5827565170356735\n",
      "Regression score at exercise date 5 0.5238983918406865\n",
      "Regression score at exercise date 4 0.43953143240069137\n",
      "Regression score at exercise date 3 0.3573490799888033\n",
      "Regression score at exercise date 2 0.2452442530066059\n",
      "Regression score at exercise date 1 0.1108803322688614\n",
      "8.41 seconds needed to solve the linear program using CVXPY\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#compute true lower bounds for the new basis\n",
    "lower_bound_extended, lower_bound_extended_std, ls_regression_models_extended = ls_pricer.price(\n",
    "        signatures_extended_training,\n",
    "        Payoff_training,\n",
    "        signatures_extended_testing,\n",
    "        Payoff_testing\n",
    "    )\n",
    "#Repeating the dual procedure for the new basis\n",
    "upper_bound_extended, upper_bound_extended_std, MG_extended = dual_pricer.price(\n",
    "        signatures_extended_training[:M_dual,:,:],\n",
    "        Payoff_training[:M_dual,:],\n",
    "        dW_training[:M_dual,:,0],  # select first component of Brownian increments\n",
    "        signatures_extended_testing,\n",
    "        Payoff_testing,\n",
    "        dW_testing[:,:,0]  # select first component of Brownian increments\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "692d7161",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "692d7161",
    "outputId": "5811cd15-9104-4ec6-fb2a-31da9a47991c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve pricing interval: (0.05343432121740919, 0.06667238204520731)± 0.0005098966689766467 \n"
     ]
    }
   ],
   "source": [
    "print(f\"Improve pricing interval: {(float(lower_bound_extended),float(upper_bound_extended))}± {np.maximum(upper_bound_std,lower_bound_std)/np.sqrt(M2)} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b5c7df",
   "metadata": {
    "id": "17b5c7df"
   },
   "source": [
    "## Part 2: Deep log-signature optimal stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e5f596",
   "metadata": {
    "id": "b7e5f596"
   },
   "source": [
    " In forthcoming work about \"American options in rough volatility models\", we will focus on more non-linear apporaches to price American options. More precisely, we extend the primal and dual procecdure by replacing linear functionals of the signature by deep neural networks on the log-signature $\\mathbb{L}=\\mathrm{log}^\\otimes(\\mathbb{X})$. This transformed version of the signature still captures the relevant information about the past of the underlying process, but grows much slower as the signature it self with respect to the truncation. Then, in order to learn highly non-linear functionals, such as the integrand of the Doob martingale (\"derivative of the Snell-envelope\"), we apply deep feedforward neural networks $\\theta$ on the log-signature. Of course, in both methods a optimization of the hyperparameters is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kTyO0IKtbYse",
   "metadata": {
    "id": "kTyO0IKtbYse"
   },
   "source": [
    "We proceed as before, but replace the linear signature by the log-signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "54699ea8",
   "metadata": {
    "id": "54699ea8"
   },
   "outputs": [],
   "source": [
    "sig_computer_log = SignatureComputer(T, N, 3, \"log\", signature_lift=\"polynomial-vol\", poly_degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e998aed9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e998aed9",
    "outputId": "195d4128-74a3-4f42-a198-6310039f6c19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing log signature with polynomial-vol lift\n",
      "X shape: (8192, 15), vol shape: (8192, 15), A shape: (8192, 253)\n",
      "Using 15 time steps for log signature computation\n",
      "Computing log signature with polynomial-vol lift\n",
      "X shape: (8192, 15), vol shape: (8192, 15), A shape: (8192, 253)\n",
      "Using 15 time steps for log signature computation\n"
     ]
    }
   ],
   "source": [
    "log_signatures_training = sig_computer_log.compute_signature(\n",
    "    S_training, vol_training, A_training, Payoff_training,\n",
    "    dW_training[:,:,0], I_training, MM_training  # use first component\n",
    ")\n",
    "log_signatures_testing = sig_computer_log.compute_signature(\n",
    "    S_testing, vol_testing, A_testing, Payoff_testing,\n",
    "    dW_testing[:,:,0], I_testing, MM_testing  # use first component and correct I_testing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "bc7ff201",
   "metadata": {
    "id": "bc7ff201"
   },
   "outputs": [],
   "source": [
    "repo_root = os.path.abspath(\"..\")  # /Users/.../Optimal_Stopping_with_signatures\n",
    "ls_folder = os.path.join(repo_root, \"Non linear signature optimal stopping\")\n",
    "sys.path.extend([repo_root, ls_folder])\n",
    "from Deep_signatures_optimal_stopping import DeepLongstaffSchwartzPricer, DeepDualPricer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "747bdf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing log signature with polynomial-vol lift\n",
      "X shape: (8192, 15), vol shape: (8192, 15), A shape: (8192, 253)\n",
      "Using 15 time steps for log signature computation\n",
      "Computing log signature with polynomial-vol lift\n",
      "X shape: (8192, 15), vol shape: (8192, 15), A shape: (8192, 253)\n",
      "Using 15 time steps for log signature computation\n",
      "shape of dW_training (8192, 14, 2)\n",
      "shape of dW_testing (8192, 14, 2)\n"
     ]
    }
   ],
   "source": [
    "log_signatures_training = sig_computer_log.compute_signature(\n",
    "    S_training, vol_training, A_training, Payoff_training,\n",
    "    dW_training[:,:,0], I_training, MM_training  # use first component\n",
    ")\n",
    "log_signatures_testing = sig_computer_log.compute_signature(\n",
    "    S_testing, vol_testing, A_testing, Payoff_testing,\n",
    "    dW_testing[:,:,0], I_testing, MM_testing  # use first component and correct I_testing\n",
    ")\n",
    "print(\"shape of dW_training\", dW_training.shape)\n",
    "print(\"shape of dW_testing\", dW_testing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1d0eff",
   "metadata": {
    "id": "9a1d0eff"
   },
   "source": [
    "The DeepLongstaffSchwartzPricer generalizes the LinearLongstaffSchwartzPrices, where the Ridge Regression at each exercise date is replace by learning the conditional expectations via neural networks. In the following initialization we build a network with $3$ hidden layers and $16$ neurons each, between each hidden layer we apply the activation function $\\mathrm{tanh}(x)$. The remainding parameters are set to 'False'. (One can run the 'Hyperparameter_optimization_primal.py' file to optimize the choice of hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "b2da432f",
   "metadata": {
    "id": "b2da432f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression at exercise date 13\n",
      "Epoch 1/15\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0052 - mae: 0.0521\n",
      "Epoch 2/15\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0291\n",
      "Epoch 3/15\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 8.9434e-04 - mae: 0.0219\n",
      "Epoch 4/15\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.0203e-04 - mae: 0.0179\n",
      "Epoch 5/15\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.9483e-04 - mae: 0.0160\n",
      "Epoch 6/15\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.7653e-04 - mae: 0.0156\n",
      "Epoch 7/15\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.3162e-04 - mae: 0.0146\n",
      "Epoch 8/15\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.8013e-04 - mae: 0.0134\n",
      "Epoch 9/15\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.6033e-04 - mae: 0.0128\n",
      "Epoch 10/15\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.6420e-04 - mae: 0.0130\n",
      "Epoch 11/15\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.4007e-04 - mae: 0.0123\n",
      "Epoch 12/15\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2432e-04 - mae: 0.0117\n",
      "Epoch 13/15\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2058e-04 - mae: 0.0117\n",
      "Epoch 14/15\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2522e-04 - mae: 0.0118\n",
      "Epoch 15/15\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.1930e-04 - mae: 0.0115\n",
      "201/201 [==============================] - 0s 595us/step\n",
      "Regression at exercise date 12\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.4986e-04 - mae: 0.0191\n",
      "203/203 [==============================] - 0s 593us/step\n",
      "Regression at exercise date 11\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.3969e-04 - mae: 0.0175\n",
      "207/207 [==============================] - 0s 611us/step\n",
      "Regression at exercise date 10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.4273e-04 - mae: 0.0164\n",
      "213/213 [==============================] - 0s 602us/step\n",
      "Regression at exercise date 9\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.4627e-04 - mae: 0.0147\n",
      "216/216 [==============================] - 0s 609us/step\n",
      "Regression at exercise date 8\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.7617e-04 - mae: 0.0168\n",
      "221/221 [==============================] - 0s 725us/step\n",
      "Regression at exercise date 7\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 7.0545e-04 - mae: 0.0179\n",
      "226/226 [==============================] - 0s 654us/step\n",
      "Regression at exercise date 6\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 5.7440e-04 - mae: 0.0167\n",
      "232/232 [==============================] - 0s 659us/step\n",
      "Regression at exercise date 5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 5.6300e-04 - mae: 0.0167\n",
      "237/237 [==============================] - 0s 633us/step\n",
      "Regression at exercise date 4\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.8144e-04 - mae: 0.0158\n",
      "243/243 [==============================] - 0s 615us/step\n",
      "Regression at exercise date 3\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.2052e-04 - mae: 0.0158\n",
      "248/248 [==============================] - 0s 615us/step\n",
      "Regression at exercise date 2\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8802e-04 - mae: 0.0175\n",
      "252/252 [==============================] - 0s 607us/step\n",
      "Regression at exercise date 1\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5824e-04 - mae: 0.0163\n",
      "255/255 [==============================] - 0s 635us/step\n",
      "256/256 [==============================] - 0s 640us/step\n",
      "256/256 [==============================] - 0s 604us/step\n",
      "256/256 [==============================] - 0s 623us/step\n",
      "256/256 [==============================] - 0s 613us/step\n",
      "256/256 [==============================] - 0s 601us/step\n",
      "256/256 [==============================] - 0s 602us/step\n",
      "256/256 [==============================] - 0s 601us/step\n",
      "256/256 [==============================] - 0s 644us/step\n",
      "256/256 [==============================] - 0s 650us/step\n",
      "256/256 [==============================] - 0s 663us/step\n",
      "256/256 [==============================] - 0s 617us/step\n",
      "256/256 [==============================] - 0s 603us/step\n",
      "256/256 [==============================] - 0s 601us/step\n",
      "Signature data shape: (8192, 15, 8)\n",
      "Payoff data shape: (8192, 15)\n",
      "dW data shape: (8192, 14)\n",
      "Using 14 time steps instead of 252 for model building\n",
      "Using indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] for 14 exercise dates\n",
      "Using indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] for 14 exercise dates\n",
      "Model expects Payoff shape: (batch_size, 14)\n",
      "Trimmed Payoff shape: (8192, 14)\n",
      "Epoch 1/15\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0842 - val_loss: 0.0823\n",
      "Epoch 2/15\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0832 - val_loss: 0.0823\n",
      "Epoch 3/15\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0832 - val_loss: 0.0821\n",
      "Epoch 4/15\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0830 - val_loss: 0.0822\n",
      "Epoch 5/15\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0832 - val_loss: 0.0821\n",
      "Epoch 6/15\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0831 - val_loss: 0.0823\n",
      "Epoch 7/15\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0832 - val_loss: 0.0825\n",
      "Epoch 8/15\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0830 - val_loss: 0.0822\n",
      "Epoch 9/15\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0831 - val_loss: 0.0826\n",
      "Epoch 10/15\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0833 - val_loss: 0.0829\n",
      "256/256 [==============================] - 0s 2ms/step\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "MG shape: (8192, 14)\n",
      "MG with zeros shape: (8192, 15)\n"
     ]
    }
   ],
   "source": [
    "ls_pricer = DeepLongstaffSchwartzPricer(\n",
    "    N1=N1,\n",
    "    T=T_years,\n",
    "    r=r,\n",
    "    mode=\"American Option\",\n",
    "    layers=3,\n",
    "    nodes=16,\n",
    "    activation_function='tanh',\n",
    "    batch_normalization=False,\n",
    "    regularizer=0.0,  # This is correct as float\n",
    "    dropout=False,\n",
    "    layer_normalization=False\n",
    ")\n",
    "\n",
    "dual_pricer = DeepDualPricer(\n",
    "    N1=N1,\n",
    "    N=N,\n",
    "    T=T_years,\n",
    "    r=r,\n",
    "    layers=3,\n",
    "    nodes=16,\n",
    "    activation_function='relu',\n",
    "    batch_normalization=False,\n",
    "    regularizer=0.0,  # ERROR: should be float, not boolean\n",
    "    dropout=False,\n",
    "    attention_layer=False,\n",
    "    layer_normalization=False\n",
    ")\n",
    "# LS pricer call is correct\n",
    "lower_bound_deep, lower_bound_deep_std, ls_regression_models = ls_pricer.price(\n",
    "    log_signatures_training,\n",
    "    Payoff_training,\n",
    "    log_signatures_testing,\n",
    "    Payoff_testing,\n",
    "    M_val=0,\n",
    "    batch=2**8,\n",
    "    epochs=15,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "# Dual pricer call is correct\n",
    "y0, upper_bound_deep, upper_bound_deep_std, dual_model, dual_rule_model = dual_pricer.price(\n",
    "    log_signatures_training,\n",
    "    Payoff_training,\n",
    "    dW_training[:,:,0],  # use only first component of Brownian increments\n",
    "    log_signatures_testing,\n",
    "    Payoff_testing,\n",
    "    dW_testing[:,:,0],  # use only first component of Brownian increments\n",
    "    M_val=int(0.9*M),\n",
    "    batch=2**8,\n",
    "    epochs=15,\n",
    "    learning_rate=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9jX2tyIWchsd",
   "metadata": {
    "id": "9jX2tyIWchsd"
   },
   "source": [
    "Similarly for the dual problem, we consider the same network but use the $relu(x)$ activation instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "186917ea",
   "metadata": {
    "id": "186917ea"
   },
   "outputs": [],
   "source": [
    "# Consistent parameter usage for validation set size\n",
    "M_val_percentage = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cDQUUvN_c6wl",
   "metadata": {
    "id": "cDQUUvN_c6wl"
   },
   "source": [
    "The Deep Longstaff Schwartz uses $15$ epochs for at the last exercise date, and then one epochs at the remainding ones by initiliazing smartly. The learning rate for the Stochastic Gradient Descent is choosen as $0.001$, and we use batch sizes of $2^8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "d04e9ff6",
   "metadata": {
    "id": "d04e9ff6",
    "outputId": "8fd83460-c4c2-40ca-8718-2b02f3227db5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Longstaff-Schwartz lower bound: 0.04974901936947877 ± 0.0002335664427550186\n"
     ]
    }
   ],
   "source": [
    "print(f\"Deep Longstaff-Schwartz lower bound: {lower_bound_deep} ± {lower_bound_deep_std/np.sqrt(M2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "RsfNfQyIebJD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RsfNfQyIebJD",
    "outputId": "7fa5e436-d332-4232-c5e7-1a2784f5d8f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Dual upper bound: 0.07309462786317511 ± 0.00029150630221770954\n",
      "Pricing interval: (0.04974901936947877, 0.07309462786317511)± 0.00029150630221770954 \n"
     ]
    }
   ],
   "source": [
    "print(f\"Deep Dual upper bound: {upper_bound_deep} ± {upper_bound_deep_std/np.sqrt(M2)}\")\n",
    "print(f\"Pricing interval: {(lower_bound_deep,upper_bound_deep)}± {np.maximum(upper_bound_deep_std,lower_bound_deep_std)/np.sqrt(M2)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "bd49d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_root = os.path.abspath(\"..\")  # /Users/.../Optimal_Stopping_with_signatures\n",
    "ls_folder = os.path.join(repo_root, \"Non linear signature optimal stopping\")\n",
    "sys.path.extend([repo_root, ls_folder])\n",
    "from Deep_kernel_signature_optimal_stopping import DeepKernelLongstaffSchwartzPricer, DeepKernelDualPricer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac7f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "96187943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Define the RFF feature computation functions with corrected implementation\n",
    "\n",
    "def compute_rff_kernel_features(signatures, N1, rff_dim=128, gamma=1.0):\n",
    "    \"\"\"\n",
    "    Compute Random Fourier Features for lower bound pricer (list format)\n",
    "    \n",
    "    Args:\n",
    "        signatures: Signature data with shape [M, T_steps, feature_dim]\n",
    "        N1: Number of exercise dates\n",
    "        rff_dim: Dimension of random features (default: 128)\n",
    "        gamma: RBF kernel bandwidth parameter (default: 1.0)\n",
    "    \n",
    "    Returns:\n",
    "        List of tensors with shape [M, rff_dim*2, 1] for each exercise date\n",
    "    \"\"\"\n",
    "    M, T_steps, feature_dim = signatures.shape\n",
    "    \n",
    "    # Calculate indices based on actual data dimensions\n",
    "    actual_steps = T_steps - 1\n",
    "    subindex = [min(int((j+1)*actual_steps/N1), actual_steps) for j in range(N1)]\n",
    "    \n",
    "    print(f\"Signature data has {T_steps} time points\")\n",
    "    print(f\"Using exercise indices: {subindex}\")\n",
    "    \n",
    "    # Create list to hold RFF features for each exercise date\n",
    "    rff_features_list = []\n",
    "    \n",
    "    # For each exercise date\n",
    "    for t in range(len(subindex)):\n",
    "        idx = min(subindex[t], T_steps-1)\n",
    "        X_t = signatures[:, idx, :]\n",
    "        \n",
    "        # Generate random projection matrix for RBF kernel approximation\n",
    "        np.random.seed(42 + t)  # Different seed for each exercise date\n",
    "        W = np.random.normal(0, np.sqrt(2*gamma), (feature_dim, rff_dim))\n",
    "        \n",
    "        # Compute RFF: [cos(Wx), sin(Wx)]\n",
    "        projection = X_t @ W\n",
    "        rff_features = np.column_stack([\n",
    "            np.cos(projection),\n",
    "            np.sin(projection)\n",
    "        ]) * np.sqrt(1/rff_dim)\n",
    "        \n",
    "        # Reshape to match expected format: [M, rff_dim*2, 1]\n",
    "        rff_features = rff_features.reshape(M, rff_dim*2, 1)\n",
    "        \n",
    "        rff_features_list.append(rff_features)\n",
    "    \n",
    "    return rff_features_list\n",
    "\n",
    "def compute_rff_kernel_features_dual(signatures, N, N1, rff_dim=128, gamma=1.0):\n",
    "    \"\"\"\n",
    "    Compute Random Fourier Features for dual pricer (3D tensor format)\n",
    "    \n",
    "    Args:\n",
    "        signatures: Signature data with shape [M, T_steps, feature_dim]\n",
    "        N: Number of time steps in the discretization\n",
    "        N1: Number of exercise dates\n",
    "        rff_dim: Dimension of random features (default: 128)\n",
    "        gamma: RBF kernel bandwidth parameter (default: 1.0)\n",
    "    \n",
    "    Returns:\n",
    "        Tensor with shape [M, features, time] for all time points\n",
    "    \"\"\"\n",
    "    M, T_steps, feature_dim = signatures.shape\n",
    "    \n",
    "    # Calculate indices proportional to exercise dates\n",
    "    # We need to map our exercise indices to the full discretization grid\n",
    "    actual_steps = min(T_steps - 1, N)\n",
    "    all_indices = np.minimum(np.array([int(t * T_steps / (N+1)) for t in range(N+1)]), T_steps-1)\n",
    "    \n",
    "    print(f\"Using exercise indices for dual pricer: {all_indices[:5]}...{all_indices[-5:]}\")\n",
    "    \n",
    "    # Generate random projection matrix once\n",
    "    np.random.seed(42)\n",
    "    W = np.random.normal(0, np.sqrt(2*gamma), (feature_dim, rff_dim))\n",
    "    \n",
    "    # Extract all required signature data at once\n",
    "    X_all = signatures[:, all_indices, :]  # Shape: [M, N+1, feature_dim]\n",
    "    \n",
    "    # Reshape for batch matrix multiplication\n",
    "    X_reshaped = X_all.reshape(-1, feature_dim)  # Shape: [M*(N+1), feature_dim]\n",
    "    \n",
    "    # Compute all projections at once\n",
    "    projections = X_reshaped @ W  # Shape: [M*(N+1), rff_dim]\n",
    "    \n",
    "    # Compute RFF features\n",
    "    cos_features = np.cos(projections)\n",
    "    sin_features = np.sin(projections)\n",
    "    rff_features = np.column_stack([cos_features, sin_features]) * np.sqrt(1/rff_dim)\n",
    "    \n",
    "    # Reshape back to original dimensions\n",
    "    full_rff = rff_features.reshape(M, N+1, rff_dim*2)\n",
    "    \n",
    "    # Transpose to match expected format: [M, features, time]\n",
    "    return np.transpose(full_rff, (0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "565afbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing kernel features for lower bound...\n",
      "Signature data has 15 time points\n",
      "Using exercise indices: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Signature data has 15 time points\n",
      "Using exercise indices: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Computing kernel features for upper bound...\n",
      "Using exercise indices for dual pricer: [0 1 2 3 4]...[10 11 12 13 14]\n",
      "Using exercise indices for dual pricer: [0 1 2 3 4]...[10 11 12 13 14]\n",
      "Initializing kernel-based lower bound...\n",
      "Computing kernel-based lower bound...\n",
      "Model: \"sequential_214\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_139 (B  (None, 128)               512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer_normalization_834 (L  (None, 128)               256       \n",
      " ayerNormalization)                                              \n",
      "                                                                 \n",
      " dense_992 (Dense)           (None, 32)                4128      \n",
      "                                                                 \n",
      " layer_normalization_835 (L  (None, 32)                64        \n",
      " ayerNormalization)                                              \n",
      "                                                                 \n",
      " layer_normalization_836 (L  (None, 32)                64        \n",
      " ayerNormalization)                                              \n",
      "                                                                 \n",
      " dense_993 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " layer_normalization_837 (L  (None, 32)                64        \n",
      " ayerNormalization)                                              \n",
      "                                                                 \n",
      " layer_normalization_838 (L  (None, 32)                64        \n",
      " ayerNormalization)                                              \n",
      "                                                                 \n",
      " dense_994 (Dense)           (None, 32)                1056      \n",
      "                                                                 \n",
      " layer_normalization_839 (L  (None, 32)                64        \n",
      " ayerNormalization)                                              \n",
      "                                                                 \n",
      " dense_995 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7361 (28.75 KB)\n",
      "Trainable params: 7105 (27.75 KB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n",
      "Regression at exercise date 13\n",
      "Epoch 1/15\n",
      "21/26 [=======================>......] - ETA: 0s - loss: 0.5109 - r2_score: -99.9116 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dm/gdlv246s3gb0zcz60k72q8yw0000gq/T/ipykernel_95063/2970133649.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mlayer_normalization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Computing kernel-based lower bound...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m lower_bound_kernel, lower_bound_kernel_std, kernel_models = kernel_pricer.price(\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mkernel_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mkernel_testing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mPayoff_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/Non linear signature optimal stopping/Deep_kernel_signature_optimal_stopping.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, kernel_training, kernel_testing, Payoff_training, Payoff_testing, batch, epochs, learning_rate)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Regression at exercise date {j}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                 regr[j-1].fit(\n\u001b[0m\u001b[1;32m    213\u001b[0m                     \u001b[0mkernel_exercise_training\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mITM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                     \u001b[0mvalue_training\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mITM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/Non linear signature optimal stopping/Deep_kernel_signature_optimal_stopping.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, epochs, batch_size, verbose, callbacks)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m             )\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error during fit: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training skipped due to error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1779\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                             \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                             \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m                 \u001b[0;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1356\u001b[0m                 run_step = tf.function(\n\u001b[1;32m   1357\u001b[0m                     \u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjit_compile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_retracing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m                 )\n\u001b[1;32m   1359\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m   1362\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1675\u001b[0m       \u001b[0;31m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m       \u001b[0;31m# applied when the caller is also in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1678\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1679\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3265\u001b[0m     \u001b[0m_require_cross_replica_or_default_context_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3267\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3268\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3269\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4065\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4066\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4067\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m                 \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/keras/src/optimizers/legacy/optimizer_v2.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mRaises\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m           \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0msome\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \"\"\"\n\u001b[0;32m--> 598\u001b[0;31m         grads_and_vars = self._compute_gradients(\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         )\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/keras/src/optimizers/legacy/optimizer_v2.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m             grads_and_vars = self._get_gradients(\n\u001b[0m\u001b[1;32m    657\u001b[0m                 \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             )\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/keras/src/optimizers/legacy/optimizer_v2.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1061\u001b[0m               output_gradients))\n\u001b[1;32m   1062\u001b[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001b[1;32m   1063\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1066\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     raise ValueError(\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gradient_tape/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0mgx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmust_reduce_x\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0mgx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m     \u001b[0mgx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mskip_input_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_input_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0mgy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmust_reduce_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   2425\u001b[0m   \u001b[0mint64\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2426\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m   \"\"\"\n\u001b[1;32m   2428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2429\u001b[0;31m   return reduce_sum_with_dims(input_tensor, axis, keepdims, name,\n\u001b[0m\u001b[1;32m   2430\u001b[0m                               _ReductionDims(input_tensor, axis))\n",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input_tensor, axis, keepdims, name, dims)\u001b[0m\n\u001b[1;32m   2437\u001b[0m                          dims=None):\n\u001b[1;32m   2438\u001b[0m   \u001b[0mkeepdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2439\u001b[0m   return _may_reduce_to_scalar(\n\u001b[1;32m   2440\u001b[0m       \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2441\u001b[0;31m       gen_math_ops._sum(input_tensor, dims, keepdims, name=name))\n\u001b[0m",
      "\u001b[0;32m~/Downloads/Optimal_Stopping_with_signatures-main/.venv/lib/python3.10/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m  12233\u001b[0m         _ctx, \"Sum\", name, input, axis, \"keep_dims\", keep_dims)\n\u001b[1;32m  12234\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12235\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12236\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 12237\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  12238\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12239\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12240\u001b[0m       return _sum_eager_fallback(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cell 2: Calculate and use RFF features for pricing with corrected implementation\n",
    "\n",
    "# Calculate both sets of features\n",
    "rff_dim = 64\n",
    "print(\"Computing kernel features for lower bound...\")\n",
    "kernel_training = compute_rff_kernel_features(log_signatures_training, N1, rff_dim=rff_dim)\n",
    "kernel_testing = compute_rff_kernel_features(log_signatures_testing, N1, rff_dim=rff_dim)\n",
    "\n",
    "# IMPORTANT: For the dual approach, we need to generate features for N1 steps\n",
    "print(\"Computing kernel features for upper bound...\")\n",
    "kernel_training_dual = compute_rff_kernel_features_dual(log_signatures_training, N1, N1, rff_dim=rff_dim)\n",
    "kernel_testing_dual = compute_rff_kernel_features_dual(log_signatures_testing, N1, N1, rff_dim=rff_dim)\n",
    "print(\"Initializing kernel-based lower bound...\")\n",
    "# 1. LOWER BOUND calculation - this works correctly\n",
    "kernel_pricer = DeepKernelLongstaffSchwartzPricer(\n",
    "    N1=N1,\n",
    "    T=T_years,\n",
    "    r=r,\n",
    "    L=rff_dim*2,\n",
    "    mode=\"American Option\",\n",
    "    layers=3,\n",
    "    nodes=32,\n",
    "    activation_function='relu',\n",
    "    batch_normalization=True,\n",
    "    regularizer=0.001,\n",
    "    dropout=False,\n",
    "    layer_normalization=True\n",
    ")\n",
    "\n",
    "print(\"Computing kernel-based lower bound...\")\n",
    "lower_bound_kernel, lower_bound_kernel_std, kernel_models = kernel_pricer.price(\n",
    "    kernel_training,\n",
    "    kernel_testing,\n",
    "    Payoff_training,\n",
    "    Payoff_testing,\n",
    "    batch=2**8,\n",
    "    epochs=15,\n",
    "    learning_rate=0.0005\n",
    ")\n",
    "\n",
    "# 2. UPPER BOUND calculation - use direct payoff, no need to expand\n",
    "print(\"Initializing kernel-based upper bound...\")\n",
    "kernel_dual_pricer = DeepKernelDualPricer(\n",
    "    N1=N1,\n",
    "    N=N1,  # Using N1 instead of N=252 here is the key change\n",
    "    T=T_years,\n",
    "    r=r,\n",
    "    layers=4,\n",
    "    nodes=32,\n",
    "    activation_function='relu',\n",
    "    batch_normalization=True,\n",
    "    regularizer=0.001,\n",
    "    dropout=True,\n",
    "    attention_layer=False,\n",
    "    layer_normalization=True,\n",
    "    mode_dim=\"1-dim\"\n",
    ")\n",
    "print(\"Computing kernel-based upper bound...\")\n",
    "try:\n",
    "    y0_kernel, upper_bound_kernel, upper_bound_kernel_std, kernel_model, kernel_rule_model = kernel_dual_pricer.price(\n",
    "        kernel_training_dual,\n",
    "        Payoff_training,\n",
    "        dW_training[:,:,0],\n",
    "        kernel_testing_dual,\n",
    "        Payoff_testing,      \n",
    "        dW_testing[:,:,0],\n",
    "        M_val=int(0.9*M),\n",
    "        batch=2**8,\n",
    "        epochs=15,\n",
    "        learning_rate=0.0005\n",
    "    )\n",
    "    \n",
    "    # Report results\n",
    "    print(f\"Deep Kernel Longstaff-Schwartz lower bound: {lower_bound_kernel} ± {lower_bound_kernel_std/np.sqrt(M2)}\")\n",
    "    print(f\"Deep Kernel Dual upper bound: {upper_bound_kernel} ± {upper_bound_kernel_std/np.sqrt(M2)}\")\n",
    "    print(f\"Kernel-based pricing interval: [{lower_bound_kernel}, {upper_bound_kernel}] ± {np.maximum(upper_bound_kernel_std, lower_bound_kernel_std)/np.sqrt(M2)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in dual pricer: {e}\")\n",
    "    print(f\"Deep Kernel Longstaff-Schwartz lower bound: {lower_bound_kernel} ± {lower_bound_kernel_std/np.sqrt(M2)}\")\n",
    "    print(\"Upper bound calculation failed - using only lower bound\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2K5Yrl-ejcN",
   "metadata": {
    "id": "a2K5Yrl-ejcN"
   },
   "source": [
    "We once again stress that the parameters for the the discretization (here $J=120$), the sample size (here $M=10^{15}$), and the signature trunaction level (here $K=3$) are not choosen big enough to get narrow gaps, but we can still already observe an improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b1b07",
   "metadata": {},
   "source": [
    "## Step 5: Contextualizing Theoretical Price in USD\n",
    "Convert the normalized model price bounds into USD per share and per contract, and print actionable trading recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abfbfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Method</th>\n",
       "      <th>Lower Bound (USD)</th>\n",
       "      <th>Upper Bound (USD)</th>\n",
       "      <th>Std Error (USD)</th>\n",
       "      <th>Price Gap (USD)</th>\n",
       "      <th>Gap (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Linear Signature</td>\n",
       "      <td>$5.32</td>\n",
       "      <td>$6.83</td>\n",
       "      <td>$0.25</td>\n",
       "      <td>$1.51</td>\n",
       "      <td>28.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Extended Linear Signature</td>\n",
       "      <td>$5.26</td>\n",
       "      <td>$7.01</td>\n",
       "      <td>$0.24</td>\n",
       "      <td>$1.75</td>\n",
       "      <td>33.27%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Deep Log-Signature</td>\n",
       "      <td>$4.92</td>\n",
       "      <td>$7.74</td>\n",
       "      <td>$0.12</td>\n",
       "      <td>$2.82</td>\n",
       "      <td>57.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Deep Kernel Method</td>\n",
       "      <td>$4.99</td>\n",
       "      <td>$12.91</td>\n",
       "      <td>$0.14</td>\n",
       "      <td>$7.92</td>\n",
       "      <td>158.88%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the normalized price bounds to actual USD values\n",
    "actual_stock_price = X0 * 100  # USD per share\n",
    "actual_strike = strike * actual_stock_price  # USD per share\n",
    "\n",
    "# Include all four methods in the list\n",
    "methods = [\n",
    "    \"Linear Signature\", \n",
    "    \"Extended Linear Signature\", \n",
    "    \"Deep Log-Signature\",\n",
    "    \"Deep Kernel Method\"  # Added the kernel method\n",
    "]\n",
    "\n",
    "# Collect all price bounds\n",
    "lower_bounds = [lower_bound, lower_bound_extended, lower_bound_deep, lower_bound_kernel]\n",
    "upper_bounds = [upper_bound, upper_bound_extended, upper_bound_deep, upper_bound_kernel]\n",
    "stds = [lower_bound_std, lower_bound_extended_std, lower_bound_deep_std, lower_bound_kernel_std]\n",
    "\n",
    "# Create a table of results\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "results = []\n",
    "for i, method in enumerate(methods):\n",
    "    usd_lower = float(lower_bounds[i]) * actual_stock_price\n",
    "    \n",
    "    # Handle the case where upper bound might not be available for kernel method\n",
    "    if i == 3 and 'upper_bound_kernel' not in locals():\n",
    "        usd_upper = float('nan')  # Use NaN if upper bound isn't available\n",
    "    else:\n",
    "        usd_upper = float(upper_bounds[i]) * actual_stock_price\n",
    "    \n",
    "    usd_std = float(stds[i]) * actual_stock_price / np.sqrt(M2)\n",
    "    \n",
    "    # Calculate gap only if upper bound exists\n",
    "    if not np.isnan(usd_upper):\n",
    "        gap = usd_upper - usd_lower\n",
    "        gap_percent = gap / usd_lower * 100\n",
    "    else:\n",
    "        gap = float('nan')\n",
    "        gap_percent = float('nan')\n",
    "    \n",
    "    results.append({\n",
    "        \"Method\": method,\n",
    "        \"Lower Bound (USD)\": f\"${usd_lower:.2f}\",\n",
    "        \"Upper Bound (USD)\": f\"${usd_upper:.2f}\" if not np.isnan(usd_upper) else \"N/A\",\n",
    "        \"Std Error (USD)\": f\"${usd_std:.2f}\",\n",
    "        \"Price Gap (USD)\": f\"${gap:.2f}\" if not np.isnan(gap) else \"N/A\",\n",
    "        \"Gap (%)\": f\"{gap_percent:.2f}%\" if not np.isnan(gap_percent) else \"N/A\"\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(HTML(results_df.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617b75c6",
   "metadata": {},
   "source": [
    "## Option Trading Interpretation\n",
    "\n",
    "Now let's interpret these results from a trading perspective. We'll evaluate the fair price range for an American put option contract (which typically represents 100 shares)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403373a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Put Option Contract Analysis (for 100 shares)\n",
      "=====================================================================\n",
      "Stock Price: $100.00\n",
      "Strike Price: $105.00\n",
      "Time to Maturity: 14 days\n",
      "Interest Rate: 5.00%\n",
      "Rough Volatility Parameters: H=0.07, η=1.9, ρ=-0.9, ξ₀=0.09\n",
      "=====================================================================\n",
      "Fair Price Range: $4.92 to $7.74 per contract\n",
      "Midpoint Price: $6.33\n",
      "=====================================================================\n",
      "Trading Recommendations:\n",
      "\n",
      "If market price is $3.94 (Below Fair Value):\n",
      "→ BUY: Market price is below fair value range\n",
      "→ Expected edge: $0.98 to $3.80 per contract\n",
      "→ Consider buying puts for protection or speculative profit\n",
      "\n",
      "If market price is $6.33 (At Fair Value):\n",
      "→ NEUTRAL: Market price is within fair value range\n",
      "→ Price is positioned 50% through the fair value range\n",
      "→ No clear edge for buying or selling\n",
      "\n",
      "If market price is $9.28 (Above Fair Value):\n",
      "→ SELL: Market price is above fair value range\n",
      "→ Expected edge: $1.55 to $4.36 per contract\n",
      "→ Consider writing puts, potentially as part of a spread strategy to limit risk\n"
     ]
    }
   ],
   "source": [
    "# Now we can calculate the fair price range for a standard options contract\n",
    "# Cell under “# For a standard options contract (100 shares)”\n",
    "shares_per_contract = 100\n",
    "contract_lower   = float(lower_bound_deep) * actual_stock_price\n",
    "contract_upper   = float(upper_bound_deep) * actual_stock_price\n",
    "contract_midpoint = (contract_lower + contract_upper) / 2\n",
    "\n",
    "print(f\"American Put Option Contract Analysis (for {shares_per_contract} shares)\")\n",
    "print(f\"=====================================================================\")\n",
    "print(f\"Stock Price: ${actual_stock_price:.2f}\")\n",
    "print(f\"Strike Price: ${actual_strike:.2f}\")\n",
    "print(f\"Time to Maturity: {T} days\")\n",
    "print(f\"Interest Rate: {r*100:.2f}%\")\n",
    "print(f\"Rough Volatility Parameters: H={H}, η={eta}, ρ={rho}, ξ₀={xi}\")\n",
    "print(f\"=====================================================================\")\n",
    "print(f\"Fair Price Range: ${contract_lower:.2f} to ${contract_upper:.2f} per contract\")\n",
    "print(f\"Midpoint Price: ${contract_midpoint:.2f}\")\n",
    "print(f\"=====================================================================\")\n",
    "\n",
    "# Trading recommendations based on market prices\n",
    "hypothetical_market_prices = [contract_lower * 0.8, contract_midpoint, contract_upper * 1.2]\n",
    "labels = [\"Below Fair Value\", \"At Fair Value\", \"Above Fair Value\"]\n",
    "\n",
    "print(\"Trading Recommendations:\")\n",
    "for price, label in zip(hypothetical_market_prices, labels):\n",
    "    print(f\"\\nIf market price is ${price:.2f} ({label}):\")\n",
    "    \n",
    "    if price < contract_lower:\n",
    "        print(\"→ BUY: Market price is below fair value range\")\n",
    "        print(f\"→ Expected edge: ${(contract_lower - price):.2f} to ${(contract_upper - price):.2f} per contract\")\n",
    "        print(\"→ Consider buying puts for protection or speculative profit\")\n",
    "    elif price > contract_upper:\n",
    "        print(\"→ SELL: Market price is above fair value range\")\n",
    "        print(f\"→ Expected edge: ${price - contract_upper:.2f} to ${price - contract_lower:.2f} per contract\")\n",
    "        print(\"→ Consider writing puts, potentially as part of a spread strategy to limit risk\")\n",
    "    else:\n",
    "        print(\"→ NEUTRAL: Market price is within fair value range\")\n",
    "        position = (price - contract_lower) / (contract_upper - contract_lower)\n",
    "        print(f\"→ Price is positioned {position:.0%} through the fair value range\")\n",
    "        if position < 0.4:\n",
    "            print(\"→ Slight bias toward buying\")\n",
    "        elif position > 0.6:\n",
    "            print(\"→ Slight bias toward selling\")\n",
    "        else:\n",
    "            print(\"→ No clear edge for buying or selling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a30e089",
   "metadata": {},
   "source": [
    "## Risk Management Considerations\n",
    "\n",
    "When trading American put options in a rough volatility environment, several risk management considerations are important:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5bf077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk Management Considerations:\n",
      "=====================================================================\n",
      "Moneyness: 0.95 (5% in-the-money)\n",
      "Time Value: $-0.08 per share\n",
      "Uncertainty Range: $2.82 per contract\n",
      "\n",
      "Recommended Risk Management Strategies:\n",
      "---------------------------------------------------------------------\n",
      "1. Position Sizing: Limit exposure to <5% of portfolio per trade\n",
      "2. Early Exercise Consideration: Monitor optimal stopping boundaries\n",
      "3. Hedging: Consider delta and vega hedging for larger positions\n",
      "4. Model Risk: Be aware model assumes H=0.07, may differ from market\n",
      "\n",
      "Practical Implementation:\n",
      "---------------------------------------------------------------------\n",
      "→ ATM option: Maximum gamma/vega exposure\n",
      "→ Most sensitive to changes in volatility and rough volatility parameters\n",
      "→ Actively monitor for optimal early exercise conditions near expiration\n",
      "\n",
      "Note: This model incorporates rough volatility effects (H=0.07) which\n",
      "traditional models like Black-Scholes miss. This can be particularly\n",
      "important for managing risk in volatile market conditions.\n"
     ]
    }
   ],
   "source": [
    "# Calculate additional risk metrics\n",
    "# In the “# Calculate additional risk metrics” cell\n",
    "percent_itm = max(0, (actual_strike - actual_stock_price) / actual_strike * 100)\n",
    "\n",
    "moneyness = actual_stock_price / actual_strike\n",
    "time_value = float(lower_bound_deep) * actual_stock_price - max(0, actual_strike - actual_stock_price)\n",
    "model_implied_volatility = 0.3  # This would typically be backed out from the model price\n",
    "\n",
    "print(\"Risk Management Considerations:\")\n",
    "print(\"=====================================================================\")\n",
    "print(f\"Moneyness: {moneyness:.2f} ({percent_itm:.0f}% in-the-money)\")\n",
    "print(f\"Time Value: ${time_value:.2f} per share\")\n",
    "print(f\"Uncertainty Range: ${(contract_upper - contract_lower):.2f} per contract\")\n",
    "print(\"\\nRecommended Risk Management Strategies:\")\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"1. Position Sizing: Limit exposure to <5% of portfolio per trade\")\n",
    "print(\"2. Early Exercise Consideration: Monitor optimal stopping boundaries\")\n",
    "print(\"3. Hedging: Consider delta and vega hedging for larger positions\")\n",
    "print(\"4. Model Risk: Be aware model assumes H={:.2f}, may differ from market\".format(H))\n",
    "\n",
    "# Additional practical advice\n",
    "print(\"\\nPractical Implementation:\")\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "if moneyness < 0.95:\n",
    "    print(\"→ Deep ITM option: Consider early exercise if dividend yield > interest rate\")\n",
    "    print(\"→ Watch for significant changes in volatility that could shift optimal exercise boundary\")\n",
    "elif moneyness > 1.05:\n",
    "    print(\"→ OTM option: Early exercise unlikely, trade like European option\")\n",
    "    print(\"→ Primary value is in insurance against downside moves\")\n",
    "else:\n",
    "    print(\"→ ATM option: Maximum gamma/vega exposure\")\n",
    "    print(\"→ Most sensitive to changes in volatility and rough volatility parameters\")\n",
    "    print(\"→ Actively monitor for optimal early exercise conditions near expiration\")\n",
    "\n",
    "print(\"\\nNote: This model incorporates rough volatility effects (H={:.2f}) which\".format(H))\n",
    "print(\"traditional models like Black-Scholes miss. This can be particularly\")\n",
    "print(\"important for managing risk in volatile market conditions.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
