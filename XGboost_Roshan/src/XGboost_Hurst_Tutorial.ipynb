{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#1E88E5\">XGBoost for Hurst Exponent Forecasting (over multiple days) </span> - Step by Step Tutorial\n",
    "\n",
    "This notebook provides a detailed walkthrough of `train_hurst.py`, a script that computes the rolling Hurst exponent of a time series and trains/evaluates an XGBoost model to forecast its future values.\n",
    "\n",
    "## <span style=\"color:#43A047\">What is the Hurst Exponent?</span>\n",
    "\n",
    "<div style=\"background-color:#EFF8FB; max-width: 700px; padding:15px; border-radius:10px; border-left:5px solid #4682B4\">\n",
    "The Hurst exponent is a measure used in time series analysis that quantifies the long-term memory of a series. It helps determine if a time series is:\n",
    "<ul>\n",
    "  <li><span style=\"color:#F44336\"><b>H < 0.5</b></span>: Anti-persistent (mean-reverting)</li>\n",
    "  <li><span style=\"color:#9E9E9E\"><b>H = 0.5</b></span>: Random walk (no memory)</li>\n",
    "  <li><span style=\"color:#4CAF50\"><b>H > 0.5</b></span>: Trend-reinforcing (persistent)</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "## <span style=\"color:#43A047\">What This Notebook Covers</span>\n",
    "\n",
    "<div style=\"display: flex; flex-wrap: wrap; gap: 10px; margin-top: 10px\">\n",
    "  <div style=\"flex: 1; min-width: 100px; background-color:#E3F2FD; padding:10px; border-radius:5px\">üìö <b>1.</b> Importing libraries</div>\n",
    "  <div style=\"flex: 1; min-width: 150px; background-color:#E8F5E9; padding:10px; border-radius:5px\">üìà <b>2.</b> Computing rolling Hurst</div>\n",
    "  <div style=\"flex: 1; min-width: 150px; background-color:#FFF8E1; padding:10px; border-radius:5px\">üíæ <b>3.</b> Loading financial data</div>\n",
    "  <div style=\"flex: 1; min-width: 150px; background-color:#F3E5F5; padding:10px; border-radius:5px\">‚öôÔ∏è <b>4.</b> Creating lagged features</div>\n",
    "  <div style=\"flex: 1; min-width: 150px; background-color:#E0F7FA; padding:10px; border-radius:5px\">üß† <b>5.</b> Training XGBoost model</div>\n",
    "  <div style=\"flex: 1; min-width: 150px; background-color:#FFEBEE; padding:10px; border-radius:5px\">üîç <b>6.</b> Evaluating performance</div>\n",
    "  <div style=\"flex: 1; min-width: 150px; background-color:#F1F8E9; padding:10px; border-radius:5px\">üîÆ <b>7.</b> Forecasting future values</div>\n",
    "  <div style=\"flex: 1; min-width: 150px; background-color:#E8EAF6; padding:10px; border-radius:5px\">üñ•Ô∏è <b>8.</b> Interactive menu system</div>\n",
    "</div>\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#1E88E5\">1. Imports and Configuration</span>\n",
    "<hr style=\"height:1px;border:none;background-color:#1E88E5\">\n",
    "\n",
    "First, let's import all the necessary libraries and set up our basic configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will be accessed from: /Users/roshanshah1/Downloads/Optimal_Stopping_with_signatures-main/XGboost_Roshan/src/data/dataset3.csv\n",
      "Models will be stored in: /Users/roshanshah1/Downloads/Optimal_Stopping_with_signatures-main/XGboost_Roshan/src/models\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for numerical operations, data manipulation, and visualization\n",
    "import numpy as np               # For numerical computations (arrays, math functions)\n",
    "import pandas as pd               # For data manipulation with DataFrames\n",
    "import matplotlib.pyplot as plt   # For creating plots and visualizations\n",
    "from pathlib import Path          # For handling file paths in a platform-independent way\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error  # For model evaluation metrics\n",
    "import logging                    # For logging status and debug messages\n",
    "import joblib                     # For saving/loading Python objects (like our trained models)\n",
    "from xgboost import XGBRegressor  # XGBoost regression model implementation\n",
    "\n",
    "# Set up basic configuration\n",
    "# How many days ahead to predict (forecast horizon)\n",
    "HORIZON = 14\n",
    "\n",
    "# Configure logging to show informational messages with timestamps\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Show INFO level messages and above\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'  # Include timestamp and message level\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define paths for data files and model storage\n",
    "# Since we're in a Jupyter notebook, we'll use the current working directory\n",
    "notebook_dir = Path.cwd()\n",
    "DATA_PATH = notebook_dir / 'data' / 'dataset3.csv'  # Path to raw CSV data\n",
    "DATA_PICKLE = notebook_dir / 'data' / 'dataset3.pkl'  # Path to cached pickle data\n",
    "\n",
    "# Create directory for saving trained models\n",
    "MODELS_DIR = notebook_dir / 'models'\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "print(f\"Data will be accessed from: {DATA_PATH}\")\n",
    "print(f\"Models will be stored in: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#FF8F00\">2. Computing the Rolling Hurst Exponent</span>\n",
    "<hr style=\"height:1px;border:none;background-color:#FF8F00\">\n",
    "\n",
    "This function calculates the Hurst exponent using Rescaled Range (R/S) analysis over a rolling window. The Hurst exponent measures the long-term memory or persistence of a time series.\n",
    "\n",
    "<div style=\"background-color:#FFF8E1; max-width: 700px; padding:15px; border-radius:10px; border-left:5px solid #FFB300\">\n",
    "<span style=\"font-size:1.1em\">üîë <b>Key Concepts:</b></span>\n",
    "<ul>\n",
    "  <li><b>Window size</b>: 2<sup>power</sup> determines how many data points we use for each calculation</li>\n",
    "  <li><b>R/S Analysis</b>: Calculates the ratio of the range to the standard deviation at different time scales</li>\n",
    "  <li><b>Slope of log-log plot</b>: The slope of the line relating log(R/S) to log(time scale) gives us the Hurst exponent</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_rolling_hurst(returns: np.ndarray, power: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the Hurst exponent using R/S analysis over a rolling window of size 2^power.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    returns : np.ndarray\n",
    "        Time series data (e.g., asset returns) to analyze\n",
    "    power : int\n",
    "        Power of 2 to determine window size (window size = 2^power)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray\n",
    "        Array of Hurst exponents calculated over rolling windows\n",
    "    \"\"\"\n",
    "    # Convert input to numpy array if it's not already\n",
    "    if not isinstance(returns, np.ndarray):\n",
    "        returns = np.array(returns)\n",
    "        \n",
    "    # Validate the power parameter\n",
    "    if not isinstance(power, int) or power < 1:\n",
    "        raise ValueError(\"power must be a positive integer\")\n",
    "        \n",
    "    # Calculate window length as 2^power\n",
    "    n = 2**power\n",
    "    \n",
    "    # Check if we have enough data\n",
    "    if len(returns) < n:\n",
    "        raise ValueError(f\"Need at least {n} data points for power={power}\")\n",
    "        \n",
    "    # Initialize list to store Hurst exponents\n",
    "    hursts = []\n",
    "    \n",
    "    # Define the range of exponents for multi-scale analysis\n",
    "    # (from 2 to power, these will be our different time scales)\n",
    "    exponents = np.arange(2, power+1)\n",
    "    \n",
    "    # Roll the window through the data\n",
    "    for t in range(n, len(returns) + 1):\n",
    "        # Get current window of data\n",
    "        window = returns[t-n:t]\n",
    "        \n",
    "        # Store log values of R/S at different scales\n",
    "        rs_log = []\n",
    "        \n",
    "        # Calculate R/S at different time scales\n",
    "        for exp in exponents:\n",
    "            # Size of each segment at this scale\n",
    "            m = 2**exp\n",
    "            \n",
    "            # Number of segments\n",
    "            s = n // m\n",
    "            \n",
    "            # Reshape data into segments\n",
    "            segments = window.reshape(s, m)\n",
    "            \n",
    "            # Calculate cumulative deviation from mean for each segment\n",
    "            dev = np.cumsum(\n",
    "                segments - segments.mean(axis=1, keepdims=True),\n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "            # Range (R) is max deviation minus min deviation\n",
    "            R = dev.max(axis=1) - dev.min(axis=1)\n",
    "            \n",
    "            # Standard deviation (S) of each segment\n",
    "            S = segments.std(axis=1)\n",
    "            \n",
    "            # Calculate R/S ratio (avoid division by zero)\n",
    "            rs = np.where(S != 0, R/S, 0)\n",
    "            \n",
    "            # Store log2 of mean R/S value\n",
    "            rs_log.append(np.log2(rs.mean()))\n",
    "        \n",
    "        # Fit a line to log(R/S) vs log(time scale)\n",
    "        # The slope of this line is the Hurst exponent\n",
    "        hursts.append(np.polyfit(exponents, rs_log, 1)[0])\n",
    "        \n",
    "    return np.array(hursts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#7B1FA2\">3. Data Loading Function</span>\n",
    "<hr style=\"height:1px;border:none;background-color:#7B1FA2\">\n",
    "\n",
    "<div style=\"background-color:#F3E5F5; width:95%; padding:15px; border-radius:10px; border-left:5px solid #7B1FA2\">\n",
    "This function handles loading the price dataset. It checks if a cached version exists (for faster loading) and otherwise loads from CSV.\n",
    "\n",
    "<p style=\"margin-top:10px\">\n",
    "üí° <b>Pro tip:</b> Using pickle for caching data significantly improves loading speed for large datasets!\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the price dataset from CSV or cache, sort by date,\n",
    "    and return a pandas DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing price data sorted by date\n",
    "    \"\"\"\n",
    "    # First, check if a cached (pickled) version of the data exists\n",
    "    if DATA_PICKLE.exists():\n",
    "        # Load from the pickle file (much faster than CSV)\n",
    "        df = pd.read_pickle(DATA_PICKLE)\n",
    "        logger.info(f\"Loaded data from cache: {DATA_PICKLE}\")\n",
    "    else:\n",
    "        # If no cache exists, load from CSV\n",
    "        df = pd.read_csv(\n",
    "            DATA_PATH,\n",
    "            parse_dates=['date'],  # Convert 'date' column to datetime\n",
    "            low_memory=False       # Avoid warnings for mixed data types\n",
    "        )\n",
    "        # Sort the data by date\n",
    "        df.sort_values('date', inplace=True)\n",
    "        \n",
    "        # Cache the data for faster future loading\n",
    "        df.to_pickle(DATA_PICKLE)\n",
    "        logger.info(f\"Saved data to cache: {DATA_PICKLE}\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#26A69A\">4. Creating Lagged Features for Time Series Forecasting</span>\n",
    "<hr style=\"height:1px;border:none;background-color:#26A69A\">\n",
    "\n",
    "This function creates lagged features for time series forecasting. Lagged features are simply past values of the time series that are used to predict future values.\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; margin: 20px 0;\">\n",
    "  <div style=\"background-color:#E0F2F1; padding:15px; border-radius:10px; width:90%\">\n",
    "    <span style=\"color:#00695C; font-weight:bold\">Key Concepts:</span>\n",
    "    <table style=\"width:100%; border-collapse: collapse; margin-top: 10px\">\n",
    "      <tr style=\"background-color:#B2DFDB\">\n",
    "        <th style=\"padding:8px; text-align:left\">Concept</th>\n",
    "        <th style=\"padding:8px; text-align:left\">Description</th>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"padding:8px; border-bottom:1px solid #ddd\"><b>Lag</b></td>\n",
    "        <td style=\"padding:8px; border-bottom:1px solid #ddd\">Using past values (t-1, t-2, ..., t-k) to predict the current value (t)</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"padding:8px; border-bottom:1px solid #ddd\"><b>Feature Matrix X</b></td>\n",
    "        <td style=\"padding:8px; border-bottom:1px solid #ddd\">Each row contains k consecutive past values</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"padding:8px\"><b>Target Vector y</b></td>\n",
    "        <td style=\"padding:8px\">Contains the value we want to predict (the value at time t)</td>\n",
    "      </tr>\n",
    "    </table>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lagged_features(series: pd.Series, k: int):\n",
    "    \"\"\"\n",
    "    Generate lagged features matrix X and target vector y from a time series.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series : pd.Series\n",
    "        Time series data to create lagged features from\n",
    "    k : int\n",
    "        Number of lagged values to use as features\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    (np.ndarray, np.ndarray)\n",
    "        X: Feature matrix where each row contains k consecutive past values\n",
    "        y: Target vector containing the values to predict\n",
    "    \"\"\"\n",
    "    # Convert series to a numpy array for faster processing\n",
    "    vals = series.values\n",
    "    \n",
    "    # Initialize empty lists for features and targets\n",
    "    X, y = [], []\n",
    "    \n",
    "    # For each point in the time series (starting from position k)\n",
    "    for i in range(k, len(vals)):\n",
    "        # Add the k previous values as features\n",
    "        X.append(vals[i-k:i])\n",
    "        # Add the current value as the target\n",
    "        y.append(vals[i])\n",
    "    \n",
    "    # Convert lists to numpy arrays and return\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#00897B\">5. Training an XGBoost Model</span>\n",
    "<hr style=\"height:1px;border:none;background-color:#00897B\">\n",
    "\n",
    "This function trains an XGBoost regression model on lagged values of the Hurst exponent series.\n",
    "\n",
    "<div style=\"background-color:#E0F2F1; max-width:1200px; padding:15px; border-radius:10px; border-left:5px solid #00897B\">\n",
    "<span style=\"font-size:1.1em\">üîë <b>Key Concepts:</b></span>\n",
    "\n",
    "<div style=\"display: flex; flex-wrap: wrap; gap: 10px; margin-top: 10px\">\n",
    "  <div style=\"flex: 1; min-width: 200px; background-color:#B2DFDB; padding:10px; border-radius:5px\">\n",
    "    <b>XGBoost</b><br>A powerful gradient boosting algorithm that often achieves state-of-the-art results\n",
    "  </div>\n",
    "  <div style=\"flex: 1; min-width: 200px; background-color:#B2DFDB; padding:10px; border-radius:5px\">\n",
    "    <b>Train/Test Split</b><br>Dividing the data into a training set and test set based on time\n",
    "  </div>\n",
    "  <div style=\"flex: 1; min-width: 200px; background-color:#B2DFDB; padding:10px; border-radius:5px\">\n",
    "    <b>Model Saving</b><br>Saving the trained model to disk for later use\n",
    "  </div>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_only(hurst_series: pd.Series, train_frac: float, k: int, xgb_params: dict):\n",
    "    \"\"\"\n",
    "    Train a pure XGBoost model on lagged Hurst series.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    hurst_series : pd.Series\n",
    "        Series of Hurst exponent values\n",
    "    train_frac : float\n",
    "        Fraction of data to use for training (0 to 1)\n",
    "    k : int\n",
    "        Number of lagged values to use as features\n",
    "    xgb_params : dict\n",
    "        Parameters for the XGBoost model\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    XGBRegressor\n",
    "        Trained XGBoost model\n",
    "    \"\"\"\n",
    "    # Split data into training and test sets based on time\n",
    "    # (first train_frac portion for training)\n",
    "    split = int(len(hurst_series) * train_frac)\n",
    "    train = hurst_series.iloc[:split]\n",
    "    \n",
    "    # Create lagged features for training data\n",
    "    X_tr, y_tr = make_lagged_features(train, k)\n",
    "    \n",
    "    # Initialize and train the XGBoost model\n",
    "    xgb_only = XGBRegressor(**xgb_params)\n",
    "    xgb_only.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Save the trained model to disk for later use\n",
    "    joblib.dump(xgb_only, MODELS_DIR / 'xgb_only.pkl')\n",
    "    logger.info(\"Pure XGBoost model saved to %s\", MODELS_DIR)\n",
    "    \n",
    "    return xgb_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#D81B60\">6. Evaluating Model Performance</span>\n",
    "<hr style=\"height:1px;border:none;background-color:#D81B60\">\n",
    "\n",
    "This function evaluates the trained XGBoost model on the test set and visualizes the results.\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between; flex-wrap: wrap; gap: 15px; margin: 15px 0;\">\n",
    "  <div style=\"flex: 1; min-width: 200px; background-color:#FCE4EC; padding:15px; border-radius:10px; border-top:4px solid #D81B60\">\n",
    "    <h4 style=\"margin-top:0; color:#AD1457\">Test Set</h4>\n",
    "    <p>Using unseen data to evaluate model performance is crucial for assessing how well the model will perform on new data.</p>\n",
    "  </div>\n",
    "  <div style=\"flex: 1; min-width: 200px; background-color:#FCE4EC; padding:15px; border-radius:10px; border-top:4px solid #D81B60\">\n",
    "    <h4 style=\"margin-top:0; color:#AD1457\">Error Metrics</h4>\n",
    "    <p>We use Mean Squared Error (MSE) and Mean Absolute Error (MAE) to quantify prediction accuracy.</p>\n",
    "  </div>\n",
    "  <div style=\"flex: 1; min-width: 200px; background-color:#FCE4EC; padding:15px; border-radius:10px; border-top:4px solid #D81B60\">\n",
    "    <h4 style=\"margin-top:0; color:#AD1457\">Visualization</h4>\n",
    "    <p>Plotting actual vs predicted values helps visually assess model performance and identify patterns.</p>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_xgb_only(hurst_series: pd.Series, xgb_only, k: int, test_frac: float):\n",
    "    \"\"\"\n",
    "    Evaluate pure XGBoost model on test split and plot results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    hurst_series : pd.Series\n",
    "        Series of Hurst exponent values\n",
    "    xgb_only : XGBRegressor\n",
    "        Trained XGBoost model\n",
    "    k : int\n",
    "        Number of lagged values used as features\n",
    "    test_frac : float\n",
    "        Fraction of data to use for testing (0 to 1)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    (float, float)\n",
    "        MSE and MAE on the test set\n",
    "    \"\"\"\n",
    "    # Split data into training and test sets based on time\n",
    "    # (last test_frac portion for testing)\n",
    "    split = int(len(hurst_series) * (1 - test_frac))\n",
    "    test = hurst_series.iloc[split:]\n",
    "    \n",
    "    # Create lagged features for test data\n",
    "    X_te, y_te = make_lagged_features(test, k)\n",
    "    \n",
    "    # Use the model to make predictions on test data\n",
    "    y_pred = xgb_only.predict(X_te)\n",
    "    \n",
    "    # Calculate error metrics\n",
    "    mse = mean_squared_error(y_te, y_pred)\n",
    "    mae = mean_absolute_error(y_te, y_pred)\n",
    "    \n",
    "    # Log the results\n",
    "    logger.info(\"XGBoost-only results ‚Äì MSE: %.4f, MAE: %.4f\", mse, mae)\n",
    "    \n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(12,6))\n",
    "    \n",
    "    # Get dates for the test set (need to skip the first k points because of lagging)\n",
    "    dates_te = test.index[k:]\n",
    "    \n",
    "    # Plot actual values\n",
    "    plt.plot(dates_te, y_te, 'k-', label='Actual Hurst')\n",
    "    \n",
    "    # Plot predicted values\n",
    "    plt.plot(dates_te, y_pred, 'g--', label='XGB-only Forecast')\n",
    "    \n",
    "    # Add title and labels\n",
    "    plt.title('XGBoost-only: Actual vs Forecast Hurst Exponent')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Hurst Exponent')\n",
    "    \n",
    "    # Add legend, grid, and format plot\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#43A047\">7. Forecasting Future Hurst Values</span>\n",
    "<hr style=\"height:1px;border:none;background-color:#43A047\">\n",
    "\n",
    "This function generates future forecasts using the trained XGBoost model.\n",
    "\n",
    "<div style=\"background-color:#E8F5E9; padding:20px; border-radius:10px; border-left:5px solid #43A047\">\n",
    "<span style=\"font-size:1.1em\">üîë <b>Key Concepts:</b></span>\n",
    "\n",
    "<ul style=\"list-style-type: none; padding-left: 10px;\">\n",
    "  <li style=\"margin-bottom:10px; padding-left:25px; background: url('data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"%2343A047\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22 11.08V12a10 10 0 1 1-5.93-9.14\"></path><polyline points=\"22 4 12 14.01 9 11.01\"></polyline></svg>') no-repeat left center;\">\n",
    "    <b>Recursive Forecasting</b>: Using predictions as inputs for future predictions\n",
    "  </li>\n",
    "  <li style=\"margin-bottom:10px; padding-left:25px; background: url('data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"%2343A047\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22 11.08V12a10 10 0 1 1-5.93-9.14\"></path><polyline points=\"22 4 12 14.01 9 11.01\"></polyline></svg>') no-repeat left center;\">\n",
    "    <b>Forecast Horizon</b>: Number of future time periods to predict\n",
    "  </li>\n",
    "  <li style=\"padding-left:25px; background: url('data:image/svg+xml;utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"%2343A047\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22 11.08V12a10 10 0 1 1-5.93-9.14\"></path><polyline points=\"22 4 12 14.01 9 11.01\"></polyline></svg>') no-repeat left center;\">\n",
    "    <b>Visualization</b>: Plotting historical and forecasted values\n",
    "  </li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_xgb_only(hurst_series: pd.Series, xgb_only, periods: int, k: int):\n",
    "    \"\"\"\n",
    "    Generate future forecasts using pure XGBoost model recursively.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    hurst_series : pd.Series\n",
    "        Series of Hurst exponent values\n",
    "    xgb_only : XGBRegressor\n",
    "        Trained XGBoost model\n",
    "    periods : int\n",
    "        Number of future periods to forecast\n",
    "    k : int\n",
    "        Number of lagged values used as features\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with dates and forecasted values\n",
    "    \"\"\"\n",
    "    # Create a copy of historical values to avoid modifying the original\n",
    "    hist = list(hurst_series.values)\n",
    "    \n",
    "    # Initialize list to store predictions\n",
    "    preds = []\n",
    "    \n",
    "    # Generate predictions for each future period\n",
    "    for _ in range(periods):\n",
    "        # If we don't have enough historical values yet, default to 0\n",
    "        if len(hist) < k:\n",
    "            p = 0\n",
    "        else:\n",
    "            # Use the model to predict the next value\n",
    "            p = xgb_only.predict(np.array(hist[-k:]).reshape(1, -1))[0]\n",
    "        \n",
    "        # Store the prediction\n",
    "        preds.append(p)\n",
    "        \n",
    "        # Add the prediction to historical values for recursive forecasting\n",
    "        hist.append(p)\n",
    "    \n",
    "    # Generate future dates starting from the day after the last historical date\n",
    "    # 'B' frequency means business days (Monday to Friday)\n",
    "    dates = pd.date_range(\n",
    "        hurst_series.index[-1] + pd.Timedelta(days=1), \n",
    "        periods=periods, \n",
    "        freq='B'\n",
    "    )\n",
    "    \n",
    "    # Return DataFrame with dates and forecasts\n",
    "    return pd.DataFrame({'ds': dates, 'yhat': np.array(preds)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#3949AB\">8. Interactive Menu Function</span>\n",
    "<hr style=\"height:1px;border:none;background-color:#3949AB\">\n",
    "\n",
    "<div style=\"background-color:#E8EAF6; padding:15px; border-radius:10px; border-left:5px solid #3949AB\">\n",
    "This function provides an interactive menu for users to choose what action to perform.\n",
    "\n",
    "<span style=\"display:block; margin-top:10px; font-style:italic; color:#283593\">üí° The menu makes it easy to train, evaluate, or generate forecasts with either custom or default parameters.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_menu():\n",
    "    \"\"\"\n",
    "    Display an interactive menu and get user's choice.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        User's menu choice\n",
    "    \"\"\"\n",
    "    # Display menu options\n",
    "    print(\"Select action:\")\n",
    "    print(\"0: Train XGBoost model (interactive)\")\n",
    "    print(\"1: Evaluate XGBoost model (interactive)\")\n",
    "    print(\"2: Forecast XGBoost model (interactive)\")\n",
    "    print(\"4: Quick train XGBoost with defaults\")\n",
    "    print(\"5: Quick evaluate XGBoost with defaults\")\n",
    "    print(\"6: Quick forecast XGBoost with defaults\")\n",
    "    \n",
    "    # Get user's choice\n",
    "    choice = input(\"Enter choice (0,1,2,4,5,6): \")\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#5E35B1\">9. Main Function</span>\n",
    "<hr style=\"height:1px;border:none;background-color:#5E35B1\">\n",
    "\n",
    "<div style=\"background-color:#EDE7F6; padding:15px; border-radius:10px; border-left:5px solid #5E35B1\">\n",
    "This is the main entry point of the program. It shows the menu, gets the user's choice, computes the Hurst series, and performs the requested action.\n",
    "\n",
    "<span style=\"display:block; margin-top:10px; color:#4527A0\">üöÄ <b>Execution flow:</b> Display menu ‚Üí Get user choice ‚Üí Load data ‚Üí Compute Hurst ‚Üí Perform requested action</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main entry point: show menu, get user choice, compute Hurst series,\n",
    "    and train/evaluate/forecast the XGBoost model as requested.\n",
    "    \"\"\"\n",
    "    # Log start of execution\n",
    "    logger.info(\"Starting main execution...\")\n",
    "    \n",
    "    # Display menu and get user's choice\n",
    "    mode = interactive_menu().strip()\n",
    "    \n",
    "    # Validate user's choice\n",
    "    if mode not in ['0','1','2','4','5','6']:\n",
    "        logger.error(\"Invalid mode selected. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Get parameters based on user's choice (interactive or defaults)\n",
    "    if mode in ['0','1','2']:  # Interactive mode\n",
    "        # Get user input for various parameters\n",
    "        power = int(input(\"Enter power for rolling Hurst (default 6): \") or 6)\n",
    "        ticker = input(\"Enter ticker (default AAPL): \") or 'AAPL'\n",
    "        train_frac = float(input(\"Enter train fraction (default 0.8): \") or 0.8)\n",
    "        test_frac = 1 - train_frac\n",
    "        k = int(input(\"Enter lag depth k (default 5): \") or 5)\n",
    "        xgb_params = {\n",
    "            'n_estimators': int(input(\"Enter n_estimators (100): \") or 100),\n",
    "            'learning_rate': float(input(\"Enter learning_rate (0.1): \") or 0.1)\n",
    "        }\n",
    "        periods = int(input(\"Enter forecast days (default 14): \") or HORIZON)\n",
    "    else:  # Default mode\n",
    "        # Use default parameters\n",
    "        power, ticker = 5, 'AAPL'\n",
    "        train_frac, test_frac = 0.8, 0.2\n",
    "        k = 5\n",
    "        xgb_params = {'n_estimators': 100, 'learning_rate': 0.1}\n",
    "        periods = HORIZON\n",
    "\n",
    "    # Load data and filter by ticker symbol\n",
    "    df_all = load_data()\n",
    "    df_t = df_all[df_all['ticker'] == ticker].sort_values('date')\n",
    "    returns = df_t['return'].values\n",
    "\n",
    "    # Compute rolling Hurst exponent series\n",
    "    hurst_vals = compute_rolling_hurst(returns, power)\n",
    "    dates = df_t['date']\n",
    "    start_index = 2**power - 1\n",
    "    hurst_series = pd.Series(hurst_vals, index=dates[start_index:])\n",
    "\n",
    "    # Execute requested action based on user's choice\n",
    "    if mode in ['0', '4']:  # Train model\n",
    "        train_xgb_only(hurst_series, train_frac, k, xgb_params)\n",
    "    elif mode in ['1', '5']:  # Evaluate model\n",
    "        xgb_only = joblib.load(MODELS_DIR / 'xgb_only.pkl')\n",
    "        evaluate_xgb_only(hurst_series, xgb_only, k, test_frac)\n",
    "    elif mode in ['2', '6']:  # Forecast\n",
    "        xgb_only = joblib.load(MODELS_DIR / 'xgb_only.pkl')\n",
    "        df_fc = forecast_xgb_only(hurst_series, xgb_only, periods, k)\n",
    "        logger.info(\"XGBoost-only forecast:\\n%s\", df_fc)\n",
    "        \n",
    "        # Plot historical and forecasted values\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(hurst_series.index, hurst_series.values, 'k-', label='Historical Hurst')\n",
    "        plt.plot(df_fc['ds'], df_fc['yhat'], 'g--', label='Forecast')\n",
    "        plt.title(f'{periods}-Day Hurst Forecast for {ticker}')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Hurst Exponent')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#1976D2\">10. Running the Script</span>\n",
    "<hr style=\"height:1px;border:none;background-color:#1976D2\">\n",
    "\n",
    "<div style=\"background-color:#E3F2FD; padding:15px; border-radius:10px; border-left:5px solid #1976D2\">\n",
    "Now, let's run the script as if it were being run as a standalone Python file.\n",
    "\n",
    "<span style=\"display:block; margin-top:10px; font-weight:bold; color:#1565C0\">‚ö° Note:</span> When you run the cell below, you'll be prompted to make a selection from the menu. Follow the instructions to train, evaluate, or forecast with the XGBoost model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 07:25:58,467 - INFO - Starting main execution...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select action:\n",
      "0: Train XGBoost model (interactive)\n",
      "1: Evaluate XGBoost model (interactive)\n",
      "2: Forecast XGBoost model (interactive)\n",
      "4: Quick train XGBoost with defaults\n",
      "5: Quick evaluate XGBoost with defaults\n",
      "6: Quick forecast XGBoost with defaults\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 07:26:00,061 - INFO - Loaded data from cache: /Users/roshanshah1/Downloads/Optimal_Stopping_with_signatures-main/XGboost_Roshan/src/data/dataset3.pkl\n",
      "2025-05-20 07:26:00,223 - INFO - Pure XGBoost model saved to /Users/roshanshah1/Downloads/Optimal_Stopping_with_signatures-main/XGboost_Roshan/src/models\n"
     ]
    }
   ],
   "source": [
    "# This is equivalent to the `if __name__ == '__main__':` block in the original script\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#EF6C00; font-size:1.4em\">11. Summary</span>\n",
    "<hr style=\"height:2px;border:none;background-color:#EF6C00\">\n",
    "\n",
    "This notebook has walked through all the components of the `train_hurst.py` script:\n",
    "\n",
    "<div style=\"display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 15px; margin: 20px 0;\">\n",
    "  <div style=\"background-color:#FFF3E0; padding:15px; border-radius:10px; border-top:4px solid #EF6C00\">\n",
    "    <h4 style=\"margin-top:0; color:#E65100\">1. Computing the Hurst Exponent</h4>\n",
    "    <p>We learned how to calculate the Hurst exponent using R/S analysis, which measures the long-term memory of a time series.</p>\n",
    "  </div>\n",
    "  <div style=\"background-color:#FFF3E0; padding:15px; border-radius:10px; border-top:4px solid #EF6C00\">\n",
    "    <h4 style=\"margin-top:0; color:#E65100\">2. Data Preparation</h4>\n",
    "    <p>We loaded financial data, filtered by ticker symbol, and computed the rolling Hurst exponent.</p>\n",
    "  </div>\n",
    "  <div style=\"background-color:#FFF3E0; padding:15px; border-radius:10px; border-top:4px solid #EF6C00\">\n",
    "    <h4 style=\"margin-top:0; color:#E65100\">3. Feature Engineering</h4>\n",
    "    <p>We created lagged features for time series forecasting to capture temporal patterns in the data.</p>\n",
    "  </div>\n",
    "  <div style=\"background-color:#FFF3E0; padding:15px; border-radius:10px; border-top:4px solid #EF6C00\">\n",
    "    <h4 style=\"margin-top:0; color:#E65100\">4. Model Training</h4>\n",
    "    <p>We trained an XGBoost model to forecast future Hurst exponent values based on historical patterns.</p>\n",
    "  </div>\n",
    "  <div style=\"background-color:#FFF3E0; padding:15px; border-radius:10px; border-top:4px solid #EF6C00\">\n",
    "    <h4 style=\"margin-top:0; color:#E65100\">5. Model Evaluation</h4>\n",
    "    <p>We evaluated the model's performance using MSE and MAE metrics, and visualized the results.</p>\n",
    "  </div>\n",
    "  <div style=\"background-color:#FFF3E0; padding:15px; border-radius:10px; border-top:4px solid #EF6C00\">\n",
    "    <h4 style=\"margin-top:0; color:#E65100\">6. Forecasting</h4>\n",
    "    <p>We used the trained model to forecast future Hurst exponent values through recursive prediction.</p>\n",
    "  </div>\n",
    "  <div style=\"background-color:#FFF3E0; padding:15px; border-radius:10px; border-top:4px solid #EF6C00\">\n",
    "    <h4 style=\"margin-top:0; color:#E65100\">7. Interactive Menu</h4>\n",
    "    <p>We provided an interactive interface for users to choose what action to perform with custom parameters.</p>\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
